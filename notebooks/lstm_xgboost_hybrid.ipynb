{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b7a690",
   "metadata": {},
   "source": [
    "## 1. 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d658e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow版本: 2.20.0\n",
      "XGBoost版本: 3.1.2\n",
      "✅ 库导入完成\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 深度学习\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# 数据预处理\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 设置绘图样式\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "print(f\"XGBoost版本: {xgb.__version__}\")\n",
    "print(\"✅ 库导入完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055df674",
   "metadata": {},
   "source": [
    "## 2. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b0582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据形状: (487083, 7)\n",
      "测试数据形状: (2881, 6)\n",
      "\n",
      "训练集时间范围: 2012-01-01 10:00:00 到 2025-11-22 23:30:00\n",
      "测试集时间范围: 2025-10-23 23:30:00 到 2025-11-22 23:30:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "High",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "16168103-dd9f-4730-a500-5bcee1e717c6",
       "rows": [
        [
         "0",
         "2012-01-01 10:00:00",
         "4.58",
         "4.58",
         "4.58",
         "4.58",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "2012-01-01 10:15:00",
         "4.58",
         "4.58",
         "4.58",
         "4.58",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "2012-01-01 10:30:00",
         "4.58",
         "4.58",
         "4.58",
         "4.58",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "2012-01-01 10:45:00",
         "4.58",
         "4.58",
         "4.58",
         "4.58",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "2012-01-01 11:00:00",
         "4.58",
         "4.58",
         "4.58",
         "4.58",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 10:00:00</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 10:15:00</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 10:30:00</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 10:45:00</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 11:00:00</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Open  High   Low  Close  Volume  Target\n",
       "0 2012-01-01 10:00:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
       "1 2012-01-01 10:15:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
       "2 2012-01-01 10:30:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
       "3 2012-01-01 10:45:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
       "4 2012-01-01 11:00:00  4.58  4.58  4.58   4.58     0.0     0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# 转换时间戳\n",
    "train_df['Timestamp'] = pd.to_datetime(train_df['Timestamp'])\n",
    "test_df['Timestamp'] = pd.to_datetime(test_df['Timestamp'])\n",
    "\n",
    "# 按时间排序\n",
    "train_df = train_df.sort_values('Timestamp').reset_index(drop=True)\n",
    "test_df = test_df.sort_values('Timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"训练数据形状: {train_df.shape}\")\n",
    "print(f\"测试数据形状: {test_df.shape}\")\n",
    "print(f\"\\n训练集时间范围: {train_df['Timestamp'].min()} 到 {train_df['Timestamp'].max()}\")\n",
    "print(f\"测试集时间范围: {test_df['Timestamp'].min()} 到 {test_df['Timestamp'].max()}\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8be399",
   "metadata": {},
   "source": [
    "## 3. 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0838f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 技术指标函数定义完成\n"
     ]
    }
   ],
   "source": [
    "def create_technical_features(df, target_col='Target'):\n",
    "    \"\"\"创建技术指标特征\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 如果有OHLC数据\n",
    "    if all(col in df.columns for col in ['Open', 'High', 'Low', 'Close']):\n",
    "        # 价格特征\n",
    "        df['price_range'] = df['High'] - df['Low']\n",
    "        df['price_change'] = df['Close'] - df['Open']\n",
    "        df['price_change_pct'] = df['Close'].pct_change()\n",
    "        \n",
    "        # 移动平均\n",
    "        for window in [4, 12, 24, 96]:\n",
    "            df[f'ma_{window}'] = df['Close'].rolling(window=window).mean()\n",
    "            df[f'ma_ratio_{window}'] = df['Close'] / df[f'ma_{window}']\n",
    "        \n",
    "        # 指数移动平均\n",
    "        for span in [12, 24]:\n",
    "            df[f'ema_{span}'] = df['Close'].ewm(span=span).mean()\n",
    "        \n",
    "        # 波动率\n",
    "        df['volatility_24'] = df['Close'].rolling(window=24).std()\n",
    "        df['volatility_96'] = df['Close'].rolling(window=96).std()\n",
    "        \n",
    "        # RSI (相对强弱指标)\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / (loss + 1e-8)\n",
    "        df['rsi'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # MACD\n",
    "        exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "        exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "        df['macd'] = exp1 - exp2\n",
    "        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "        df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "        \n",
    "        # 布林带\n",
    "        df['bb_middle'] = df['Close'].rolling(window=20).mean()\n",
    "        bb_std = df['Close'].rolling(window=20).std()\n",
    "        df['bb_upper'] = df['bb_middle'] + 2 * bb_std\n",
    "        df['bb_lower'] = df['bb_middle'] - 2 * bb_std\n",
    "        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']\n",
    "    \n",
    "    # 成交量特征\n",
    "    if 'Volume' in df.columns:\n",
    "        df['volume_ma_24'] = df['Volume'].rolling(window=24).mean()\n",
    "        df['volume_ratio'] = df['Volume'] / (df['volume_ma_24'] + 1e-8)\n",
    "    \n",
    "    # 时间特征\n",
    "    df['hour'] = df['Timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['Timestamp'].dt.dayofweek\n",
    "    df['day_of_month'] = df['Timestamp'].dt.day\n",
    "    df['month'] = df['Timestamp'].dt.month\n",
    "    \n",
    "    # 周期性编码\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"✅ 技术指标函数定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3572fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集特征数: 40\n",
      "测试集特征数: 39\n"
     ]
    }
   ],
   "source": [
    "# 创建特征\n",
    "train_featured = create_technical_features(train_df)\n",
    "test_featured = create_technical_features(test_df)\n",
    "\n",
    "print(f\"训练集特征数: {train_featured.shape[1]}\")\n",
    "print(f\"测试集特征数: {test_featured.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738e9f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM特征数: 5\n",
      "XGBoost特征数: 38\n",
      "\n",
      "XGBoost特征列表:\n",
      "  1. Open\n",
      "  2. High\n",
      "  3. Low\n",
      "  4. Close\n",
      "  5. Volume\n",
      "  6. price_range\n",
      "  7. price_change\n",
      "  8. price_change_pct\n",
      "  9. ma_4\n",
      "  10. ma_ratio_4\n",
      "  11. ma_12\n",
      "  12. ma_ratio_12\n",
      "  13. ma_24\n",
      "  14. ma_ratio_24\n",
      "  15. ma_96\n",
      "  16. ma_ratio_96\n",
      "  17. ema_12\n",
      "  18. ema_24\n",
      "  19. volatility_24\n",
      "  20. volatility_96\n",
      "  21. rsi\n",
      "  22. macd\n",
      "  23. macd_signal\n",
      "  24. macd_hist\n",
      "  25. bb_middle\n",
      "  26. bb_upper\n",
      "  27. bb_lower\n",
      "  28. bb_width\n",
      "  29. volume_ma_24\n",
      "  30. volume_ratio\n",
      "  31. hour\n",
      "  32. day_of_week\n",
      "  33. day_of_month\n",
      "  34. month\n",
      "  35. hour_sin\n",
      "  36. hour_cos\n",
      "  37. day_sin\n",
      "  38. day_cos\n"
     ]
    }
   ],
   "source": [
    "# 定义特征列\n",
    "# LSTM使用的序列特征（主要价格相关）\n",
    "lstm_features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# XGBoost使用的所有特征\n",
    "xgb_features = [col for col in train_featured.columns \n",
    "                if col not in ['Timestamp', 'Target'] \n",
    "                and train_featured[col].dtype in ['float64', 'int64', 'float32', 'int32']]\n",
    "\n",
    "print(f\"LSTM特征数: {len(lstm_features)}\")\n",
    "print(f\"XGBoost特征数: {len(xgb_features)}\")\n",
    "print(f\"\\nXGBoost特征列表:\")\n",
    "for i, col in enumerate(xgb_features, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a5459",
   "metadata": {},
   "source": [
    "## 4. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d655c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后训练数据: (486988, 40)\n",
      "删除的行数: 95\n"
     ]
    }
   ],
   "source": [
    "# 删除NaN\n",
    "train_clean = train_featured.dropna().reset_index(drop=True)\n",
    "print(f\"清洗后训练数据: {train_clean.shape}\")\n",
    "print(f\"删除的行数: {len(train_featured) - len(train_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20729a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM数据形状: (486988, 5)\n",
      "XGBoost数据形状: (486988, 38)\n",
      "目标数据形状: (486988, 1)\n"
     ]
    }
   ],
   "source": [
    "# 数据标准化\n",
    "lstm_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "xgb_scaler = StandardScaler()\n",
    "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# 准备LSTM数据\n",
    "lstm_data = train_clean[lstm_features].values\n",
    "lstm_scaled = lstm_scaler.fit_transform(lstm_data)\n",
    "\n",
    "# 准备XGBoost数据\n",
    "xgb_data = train_clean[xgb_features].values\n",
    "xgb_scaled = xgb_scaler.fit_transform(xgb_data)\n",
    "\n",
    "# 准备目标变量\n",
    "target_data = train_clean['Target'].values.reshape(-1, 1)\n",
    "target_scaled = target_scaler.fit_transform(target_data)\n",
    "\n",
    "print(f\"LSTM数据形状: {lstm_scaled.shape}\")\n",
    "print(f\"XGBoost数据形状: {xgb_scaled.shape}\")\n",
    "print(f\"目标数据形状: {target_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9dc99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM序列形状: (486892, 96, 5)\n",
      "XGBoost特征形状: (486892, 38)\n",
      "目标形状: (486892, 1)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(lstm_data, xgb_data, target_data, seq_length=96):\n",
    "    \"\"\"\n",
    "    创建LSTM序列数据\n",
    "    \n",
    "    seq_length=96 对应1天的数据（15分钟间隔 * 96 = 24小时）\n",
    "    \"\"\"\n",
    "    X_lstm = []\n",
    "    X_xgb = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(seq_length, len(lstm_data)):\n",
    "        X_lstm.append(lstm_data[i-seq_length:i])\n",
    "        X_xgb.append(xgb_data[i])\n",
    "        y.append(target_data[i])\n",
    "    \n",
    "    return np.array(X_lstm), np.array(X_xgb), np.array(y)\n",
    "\n",
    "# 创建序列\n",
    "SEQ_LENGTH = 96  # 1天的数据\n",
    "\n",
    "X_lstm, X_xgb, y = create_sequences(lstm_scaled, xgb_scaled, target_scaled, SEQ_LENGTH)\n",
    "\n",
    "print(f\"LSTM序列形状: {X_lstm.shape}\")\n",
    "print(f\"XGBoost特征形状: {X_xgb.shape}\")\n",
    "print(f\"目标形状: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb4e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 389513\n",
      "验证集大小: 97379\n",
      "\n",
      "LSTM训练数据: (389513, 96, 5)\n",
      "LSTM验证数据: (97379, 96, 5)\n"
     ]
    }
   ],
   "source": [
    "# 时序分割（80%训练，20%验证）\n",
    "train_size = int(len(X_lstm) * 0.8)\n",
    "\n",
    "X_lstm_train = X_lstm[:train_size]\n",
    "X_lstm_val = X_lstm[train_size:]\n",
    "\n",
    "X_xgb_train = X_xgb[:train_size]\n",
    "X_xgb_val = X_xgb[train_size:]\n",
    "\n",
    "y_train = y[:train_size]\n",
    "y_val = y[train_size:]\n",
    "\n",
    "print(f\"训练集大小: {train_size}\")\n",
    "print(f\"验证集大小: {len(X_lstm) - train_size}\")\n",
    "print(f\"\\nLSTM训练数据: {X_lstm_train.shape}\")\n",
    "print(f\"LSTM验证数据: {X_lstm_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d53a19",
   "metadata": {},
   "source": [
    "## 5. 构建LSTM模型\n",
    "\n",
    "LSTM模型用于提取时序特征，其输出将作为XGBoost的输入之一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55400206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m5\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m68,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,081</span> (461.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,081\u001b[0m (461.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,081</span> (461.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,081\u001b[0m (461.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_lstm_model(seq_length, n_features, lstm_units=[128, 64]):\n",
    "    \"\"\"\n",
    "    构建LSTM模型\n",
    "    \n",
    "    返回两个模型：\n",
    "    1. full_model: 用于训练的完整模型\n",
    "    2. feature_extractor: 用于提取特征的模型（输出最后一个LSTM层的隐藏状态）\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(seq_length, n_features))\n",
    "    \n",
    "    # 第一层LSTM\n",
    "    x = LSTM(lstm_units[0], return_sequences=True)(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # 第二层LSTM（输出隐藏状态）\n",
    "    lstm_out = LSTM(lstm_units[1], return_sequences=False)(x)\n",
    "    x = Dropout(0.2)(lstm_out)\n",
    "    \n",
    "    # 输出层\n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    # 完整模型\n",
    "    full_model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 特征提取模型（输出LSTM的隐藏状态）\n",
    "    feature_extractor = Model(inputs=inputs, outputs=lstm_out)\n",
    "    \n",
    "    return full_model, feature_extractor\n",
    "\n",
    "# 构建模型\n",
    "lstm_model, lstm_feature_extractor = build_lstm_model(\n",
    "    seq_length=SEQ_LENGTH, \n",
    "    n_features=len(lstm_features),\n",
    "    lstm_units=[128, 64]\n",
    ")\n",
    "\n",
    "# 编译模型\n",
    "lstm_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d5f7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 回调函数定义完成\n"
     ]
    }
   ],
   "source": [
    "# 定义回调函数\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"✅ 回调函数定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17206612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练LSTM模型...\n",
      "\n",
      "Epoch 1/6\n",
      "\u001b[1m 185/3044\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:10\u001b[0m 130ms/step - loss: 4.3572e-04 - mae: 0.0165"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 训练LSTM模型\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始训练LSTM模型...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_lstm_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_lstm_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ LSTM训练完成!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    398\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[1;32m--> 399\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    239\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    240\u001b[0m     ):\n\u001b[1;32m--> 241\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    243\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练LSTM模型\n",
    "print(\"开始训练LSTM模型...\\n\")\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    X_lstm_train, y_train,\n",
    "    validation_data=(X_lstm_val, y_val),\n",
    "    epochs=6,\n",
    "    batch_size=128,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✅ LSTM训练完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e833a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练历史\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='训练损失')\n",
    "axes[0].plot(history.history['val_loss'], label='验证损失')\n",
    "axes[0].set_title('LSTM模型损失', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history.history['mae'], label='训练MAE')\n",
    "axes[1].plot(history.history['val_mae'], label='验证MAE')\n",
    "axes[1].set_title('LSTM模型MAE', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5dbf6f",
   "metadata": {},
   "source": [
    "## 6. 提取LSTM特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用LSTM提取特征（最后一层LSTM的隐藏状态）\n",
    "print(\"提取LSTM特征...\")\n",
    "\n",
    "lstm_features_train = lstm_feature_extractor.predict(X_lstm_train, verbose=0)\n",
    "lstm_features_val = lstm_feature_extractor.predict(X_lstm_val, verbose=0)\n",
    "\n",
    "print(f\"训练集LSTM特征形状: {lstm_features_train.shape}\")\n",
    "print(f\"验证集LSTM特征形状: {lstm_features_val.shape}\")\n",
    "\n",
    "# 同时获取LSTM的预测值\n",
    "lstm_pred_train = lstm_model.predict(X_lstm_train, verbose=0)\n",
    "lstm_pred_val = lstm_model.predict(X_lstm_val, verbose=0)\n",
    "\n",
    "print(f\"\\nLSTM预测训练集形状: {lstm_pred_train.shape}\")\n",
    "print(f\"LSTM预测验证集形状: {lstm_pred_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92d73e",
   "metadata": {},
   "source": [
    "## 7. 构建混合特征\n",
    "\n",
    "将LSTM的输出（隐藏状态和预测值）与原始XGBoost特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并特征：原始特征 + LSTM隐藏状态 + LSTM预测值\n",
    "X_hybrid_train = np.concatenate([\n",
    "    X_xgb_train,           # 原始XGBoost特征\n",
    "    lstm_features_train,    # LSTM隐藏状态（64维）\n",
    "    lstm_pred_train         # LSTM预测值（1维）\n",
    "], axis=1)\n",
    "\n",
    "X_hybrid_val = np.concatenate([\n",
    "    X_xgb_val,\n",
    "    lstm_features_val,\n",
    "    lstm_pred_val\n",
    "], axis=1)\n",
    "\n",
    "print(f\"混合训练特征形状: {X_hybrid_train.shape}\")\n",
    "print(f\"混合验证特征形状: {X_hybrid_val.shape}\")\n",
    "print(f\"\\n特征组成:\")\n",
    "print(f\"  - 原始特征: {X_xgb_train.shape[1]}\")\n",
    "print(f\"  - LSTM隐藏状态: {lstm_features_train.shape[1]}\")\n",
    "print(f\"  - LSTM预测值: 1\")\n",
    "print(f\"  - 总计: {X_hybrid_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5dc9c3",
   "metadata": {},
   "source": [
    "## 8. 训练XGBoost模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost参数\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 1000,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_rounds': 50\n",
    "}\n",
    "\n",
    "print(\"XGBoost参数:\")\n",
    "for key, value in xgb_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练XGBoost模型\n",
    "print(\"\\n开始训练XGBoost模型...\\n\")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_hybrid_train, y_train.ravel(),\n",
    "    eval_set=[(X_hybrid_train, y_train.ravel()), (X_hybrid_val, y_val.ravel())],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "print(\"\\n✅ XGBoost训练完成!\")\n",
    "print(f\"最佳迭代次数: {xgb_model.best_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf2215",
   "metadata": {},
   "source": [
    "## 9. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6add097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在验证集上预测\n",
    "hybrid_pred_val = xgb_model.predict(X_hybrid_val)\n",
    "\n",
    "# 反标准化\n",
    "y_val_original = target_scaler.inverse_transform(y_val)\n",
    "hybrid_pred_original = target_scaler.inverse_transform(hybrid_pred_val.reshape(-1, 1))\n",
    "lstm_pred_original = target_scaler.inverse_transform(lstm_pred_val)\n",
    "\n",
    "# 计算评估指标 - 混合模型\n",
    "hybrid_rmse = np.sqrt(mean_squared_error(y_val_original, hybrid_pred_original))\n",
    "hybrid_mae = mean_absolute_error(y_val_original, hybrid_pred_original)\n",
    "hybrid_r2 = r2_score(y_val_original, hybrid_pred_original)\n",
    "\n",
    "# 计算评估指标 - 单独LSTM\n",
    "lstm_rmse = np.sqrt(mean_squared_error(y_val_original, lstm_pred_original))\n",
    "lstm_mae = mean_absolute_error(y_val_original, lstm_pred_original)\n",
    "lstm_r2 = r2_score(y_val_original, lstm_pred_original)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"模型评估结果对比\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'指标':<15} {'LSTM':<20} {'LSTM+XGBoost混合':<20}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'RMSE':<15} {lstm_rmse:<20.6f} {hybrid_rmse:<20.6f}\")\n",
    "print(f\"{'MAE':<15} {lstm_mae:<20.6f} {hybrid_mae:<20.6f}\")\n",
    "print(f\"{'R²':<15} {lstm_r2:<20.6f} {hybrid_r2:<20.6f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 计算改进比例\n",
    "rmse_improvement = (lstm_rmse - hybrid_rmse) / lstm_rmse * 100\n",
    "mae_improvement = (lstm_mae - hybrid_mae) / lstm_mae * 100\n",
    "\n",
    "print(f\"\\n混合模型相对LSTM的改进:\")\n",
    "print(f\"  RMSE改进: {rmse_improvement:.2f}%\")\n",
    "print(f\"  MAE改进: {mae_improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe23ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化预测结果对比\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 时间序列对比（最后500个点）\n",
    "display_size = min(500, len(y_val_original))\n",
    "\n",
    "axes[0, 0].plot(y_val_original[-display_size:], label='实际值', linewidth=1.5, alpha=0.7)\n",
    "axes[0, 0].plot(lstm_pred_original[-display_size:], label='LSTM预测', linewidth=1.5, alpha=0.7)\n",
    "axes[0, 0].plot(hybrid_pred_original[-display_size:], label='混合模型预测', linewidth=1.5, alpha=0.7)\n",
    "axes[0, 0].set_title(f'预测对比 (最后{display_size}个点)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('时间步')\n",
    "axes[0, 0].set_ylabel('Target')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# LSTM散点图\n",
    "axes[0, 1].scatter(y_val_original, lstm_pred_original, alpha=0.3, s=10)\n",
    "axes[0, 1].plot([y_val_original.min(), y_val_original.max()], \n",
    "                [y_val_original.min(), y_val_original.max()], 'r--', lw=2)\n",
    "axes[0, 1].set_title('LSTM: 实际值 vs 预测值', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('实际值')\n",
    "axes[0, 1].set_ylabel('预测值')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 混合模型散点图\n",
    "axes[1, 0].scatter(y_val_original, hybrid_pred_original, alpha=0.3, s=10)\n",
    "axes[1, 0].plot([y_val_original.min(), y_val_original.max()], \n",
    "                [y_val_original.min(), y_val_original.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_title('LSTM+XGBoost: 实际值 vs 预测值', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('实际值')\n",
    "axes[1, 0].set_ylabel('预测值')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 残差对比\n",
    "lstm_residuals = y_val_original.ravel() - lstm_pred_original.ravel()\n",
    "hybrid_residuals = y_val_original.ravel() - hybrid_pred_original.ravel()\n",
    "\n",
    "axes[1, 1].hist(lstm_residuals, bins=50, alpha=0.5, label=f'LSTM (std={lstm_residuals.std():.4f})')\n",
    "axes[1, 1].hist(hybrid_residuals, bins=50, alpha=0.5, label=f'混合模型 (std={hybrid_residuals.std():.4f})')\n",
    "axes[1, 1].set_title('残差分布对比', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('残差')\n",
    "axes[1, 1].set_ylabel('频数')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725bfc1f",
   "metadata": {},
   "source": [
    "## 10. 特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ec0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建特征名称列表\n",
    "feature_names = (\n",
    "    xgb_features + \n",
    "    [f'lstm_hidden_{i}' for i in range(64)] + \n",
    "    ['lstm_prediction']\n",
    ")\n",
    "\n",
    "# 获取特征重要性\n",
    "importance = xgb_model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 30 重要特征:\")\n",
    "print(importance_df.head(30).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aed2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化特征重要性\n",
    "top_n = 30\n",
    "top_features = importance_df.head(top_n)\n",
    "\n",
    "# 标记LSTM相关特征\n",
    "colors = ['red' if 'lstm' in f else 'steelblue' for f in top_features['feature']]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.barh(range(top_n), top_features['importance'].values, color=colors)\n",
    "plt.yticks(range(top_n), top_features['feature'].values)\n",
    "plt.xlabel('重要性', fontsize=12)\n",
    "plt.title(f'Top {top_n} 特征重要性 (红色=LSTM特征)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# LSTM特征重要性统计\n",
    "lstm_feature_importance = importance_df[importance_df['feature'].str.contains('lstm')]['importance'].sum()\n",
    "total_importance = importance_df['importance'].sum()\n",
    "print(f\"\\nLSTM特征总重要性占比: {lstm_feature_importance/total_importance*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c38fb",
   "metadata": {},
   "source": [
    "## 11. 测试集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ad570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备测试数据\n",
    "# 需要使用训练集最后SEQ_LENGTH个点来创建初始序列\n",
    "\n",
    "# 获取训练集最后部分\n",
    "train_tail = train_clean.tail(SEQ_LENGTH).copy()\n",
    "\n",
    "# 合并训练尾部和测试集\n",
    "combined = pd.concat([train_tail, test_featured], ignore_index=True)\n",
    "\n",
    "# 处理NaN\n",
    "combined = combined.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "print(f\"合并后数据形状: {combined.shape}\")\n",
    "print(f\"训练尾部行数: {len(train_tail)}\")\n",
    "print(f\"测试集行数: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0342e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备测试集的LSTM输入\n",
    "test_lstm_data = combined[lstm_features].values\n",
    "test_lstm_scaled = lstm_scaler.transform(test_lstm_data)\n",
    "\n",
    "# 准备测试集的XGBoost输入\n",
    "test_xgb_data = combined[xgb_features].values\n",
    "test_xgb_scaled = xgb_scaler.transform(test_xgb_data)\n",
    "\n",
    "# 创建测试序列\n",
    "X_lstm_test = []\n",
    "X_xgb_test = []\n",
    "\n",
    "for i in range(SEQ_LENGTH, len(combined)):\n",
    "    X_lstm_test.append(test_lstm_scaled[i-SEQ_LENGTH:i])\n",
    "    X_xgb_test.append(test_xgb_scaled[i])\n",
    "\n",
    "X_lstm_test = np.array(X_lstm_test)\n",
    "X_xgb_test = np.array(X_xgb_test)\n",
    "\n",
    "print(f\"测试集LSTM输入形状: {X_lstm_test.shape}\")\n",
    "print(f\"测试集XGBoost输入形状: {X_xgb_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取LSTM特征\n",
    "lstm_features_test = lstm_feature_extractor.predict(X_lstm_test, verbose=0)\n",
    "lstm_pred_test = lstm_model.predict(X_lstm_test, verbose=0)\n",
    "\n",
    "# 合并特征\n",
    "X_hybrid_test = np.concatenate([\n",
    "    X_xgb_test,\n",
    "    lstm_features_test,\n",
    "    lstm_pred_test\n",
    "], axis=1)\n",
    "\n",
    "print(f\"测试集混合特征形状: {X_hybrid_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c25d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用混合模型预测\n",
    "test_predictions_scaled = xgb_model.predict(X_hybrid_test)\n",
    "\n",
    "# 反标准化\n",
    "test_predictions = target_scaler.inverse_transform(test_predictions_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# 只保留原始测试集对应的预测（排除训练尾部）\n",
    "# 由于我们从SEQ_LENGTH开始，需要确保只取测试集的部分\n",
    "test_predictions = test_predictions[:len(test_df)]\n",
    "\n",
    "print(f\"预测完成!\")\n",
    "print(f\"预测数量: {len(test_predictions)}\")\n",
    "print(f\"预测值范围: [{test_predictions.min():.6f}, {test_predictions.max():.6f}]\")\n",
    "print(f\"预测值均值: {test_predictions.mean():.6f}\")\n",
    "print(f\"预测值标准差: {test_predictions.std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化测试集预测\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "test_timestamps = test_df['Timestamp'].values[:len(test_predictions)]\n",
    "\n",
    "# 与训练集尾部对比\n",
    "train_last = train_clean['Target'].values[-500:]\n",
    "\n",
    "axes[0].plot(range(len(train_last)), train_last, \n",
    "             label='训练集(最后500点)', linewidth=1, alpha=0.7)\n",
    "axes[0].plot(range(len(train_last), len(train_last)+len(test_predictions)), \n",
    "             test_predictions, label='测试集预测', linewidth=1.5, color='red')\n",
    "axes[0].set_title('训练集与测试集预测', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('时间步')\n",
    "axes[0].set_ylabel('Target')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 测试集预测\n",
    "axes[1].plot(test_timestamps, test_predictions, linewidth=1.5, color='red')\n",
    "axes[1].set_title('测试集预测结果', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('时间')\n",
    "axes[1].set_ylabel('预测值')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d3997",
   "metadata": {},
   "source": [
    "## 12. 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085aebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建提交文件\n",
    "submission_df = pd.DataFrame({\n",
    "    'Timestamp': test_df['Timestamp'].values[:len(test_predictions)],\n",
    "    'Prediction': test_predictions\n",
    "})\n",
    "\n",
    "# 保存提交文件\n",
    "submission_dir = Path('../submissions')\n",
    "submission_dir.mkdir(exist_ok=True)\n",
    "\n",
    "submission_file = submission_dir / 'lstm_xgboost_hybrid_submission.csv'\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"✅ 提交文件已保存: {submission_file}\")\n",
    "print(f\"\\n提交文件形状: {submission_df.shape}\")\n",
    "print(\"\\n提交文件预览:\")\n",
    "print(submission_df.head(10))\n",
    "print(\"\\n...\")\n",
    "print(submission_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交文件统计\n",
    "print(\"\\n提交文件统计:\")\n",
    "print(submission_df['Prediction'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f17098",
   "metadata": {},
   "source": [
    "## 13. 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model_dir = Path('../models')\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 保存LSTM模型\n",
    "lstm_model.save(model_dir / 'lstm_model.h5')\n",
    "lstm_feature_extractor.save(model_dir / 'lstm_feature_extractor.h5')\n",
    "print(\"✅ LSTM模型已保存\")\n",
    "\n",
    "# 保存XGBoost模型\n",
    "xgb_model.save_model(str(model_dir / 'xgboost_hybrid_model.json'))\n",
    "print(\"✅ XGBoost模型已保存\")\n",
    "\n",
    "# 保存scaler\n",
    "import joblib\n",
    "joblib.dump(lstm_scaler, model_dir / 'lstm_scaler.pkl')\n",
    "joblib.dump(xgb_scaler, model_dir / 'xgb_scaler.pkl')\n",
    "joblib.dump(target_scaler, model_dir / 'target_scaler.pkl')\n",
    "print(\"✅ Scaler已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc460237",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 模型架构\n",
    "\n",
    "本notebook实现了论文 \"Crypto Price Prediction using LSTM+XGBoost\" 中描述的混合模型：\n",
    "\n",
    "1. **LSTM组件**\n",
    "   - 两层LSTM网络（128和64个单元）\n",
    "   - 捕捉时间序列的时序依赖关系\n",
    "   - 输出隐藏状态和预测值\n",
    "\n",
    "2. **XGBoost组件**\n",
    "   - 输入：原始技术指标 + LSTM隐藏状态 + LSTM预测值\n",
    "   - 建模非线性关系\n",
    "   - 最终预测输出\n",
    "\n",
    "### 特征工程\n",
    "\n",
    "- **LSTM特征**: OHLCV数据的时间序列\n",
    "- **技术指标**: RSI, MACD, 布林带, 移动平均等\n",
    "- **时间特征**: 小时, 星期几, 月份等\n",
    "\n",
    "### 模型性能\n",
    "\n",
    "混合模型通常比单独的LSTM模型表现更好，因为：\n",
    "- LSTM捕捉时序模式\n",
    "- XGBoost利用非线性关系和辅助特征\n",
    "- 两者优势互补\n",
    "\n",
    "### 参考文献\n",
    "\n",
    "- Gautam, M. (2025). \"Crypto Price Prediction using LSTM+XGBoost\". arXiv:2506.22055"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6117a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
