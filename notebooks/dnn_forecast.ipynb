{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94fadc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1+cu121\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 随机种子\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef926851",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdf96f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: (484202, 7)\n",
      "测试集: (2881, 6)\n",
      "\n",
      "Target统计:\n",
      "count    484202.000000\n",
      "mean          0.000021\n",
      "std           0.005454\n",
      "min          -0.276799\n",
      "25%          -0.001275\n",
      "50%           0.000000\n",
      "75%           0.001384\n",
      "max           0.598299\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train_df['Timestamp'] = pd.to_datetime(train_df['Timestamp'])\n",
    "test_df['Timestamp'] = pd.to_datetime(test_df['Timestamp'])\n",
    "\n",
    "train_df = train_df.sort_values('Timestamp').reset_index(drop=True)\n",
    "test_df = test_df.sort_values('Timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"训练集: {train_df.shape}\")\n",
    "print(f\"测试集: {test_df.shape}\")\n",
    "print(f\"\\nTarget统计:\")\n",
    "print(train_df['Target'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df0391",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b37758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征后列数: 37\n"
     ]
    }
   ],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"创建特征\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 收益率\n",
    "    df['returns'] = df['Close'].pct_change()\n",
    "    df['log_returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    \n",
    "    # 移动平均\n",
    "    for w in [5, 10, 20, 50]:\n",
    "        df[f'ma_{w}'] = df['Close'].rolling(w).mean()\n",
    "        df[f'ma_ratio_{w}'] = df['Close'] / df[f'ma_{w}']\n",
    "    \n",
    "    # 波动率\n",
    "    df['volatility_5'] = df['returns'].rolling(5).std()\n",
    "    df['volatility_10'] = df['returns'].rolling(10).std()\n",
    "    df['volatility_20'] = df['returns'].rolling(20).std()\n",
    "    \n",
    "    # RSI\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    df['rsi'] = 100 - 100 / (1 + gain / (loss + 1e-10))\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = df['Close'].ewm(span=12).mean()\n",
    "    ema26 = df['Close'].ewm(span=26).mean()\n",
    "    df['macd'] = ema12 - ema26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
    "    \n",
    "    # 价格比率\n",
    "    df['high_low_ratio'] = df['High'] / (df['Low'] + 1e-10)\n",
    "    df['close_open_ratio'] = df['Close'] / (df['Open'] + 1e-10)\n",
    "    \n",
    "    # 成交量\n",
    "    df['volume_ma_10'] = df['Volume'].rolling(10).mean()\n",
    "    df['volume_ratio'] = df['Volume'] / (df['volume_ma_10'] + 1e-10)\n",
    "    \n",
    "    # 滞后特征\n",
    "    for lag in [1, 2, 3, 5, 10]:\n",
    "        df[f'returns_lag_{lag}'] = df['returns'].shift(lag)\n",
    "        df[f'close_lag_{lag}'] = df['Close'].shift(lag)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_featured = create_features(train_df)\n",
    "test_featured = create_features(test_df)\n",
    "\n",
    "print(f\"特征后列数: {train_featured.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc1d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数量: 25\n"
     ]
    }
   ],
   "source": [
    "# 选择特征列\n",
    "feature_cols = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "    'returns', 'log_returns',\n",
    "    'ma_ratio_5', 'ma_ratio_10', 'ma_ratio_20', 'ma_ratio_50',\n",
    "    'volatility_5', 'volatility_10', 'volatility_20',\n",
    "    'rsi', 'macd', 'macd_signal',\n",
    "    'high_low_ratio', 'close_open_ratio', 'volume_ratio',\n",
    "    'returns_lag_1', 'returns_lag_2', 'returns_lag_3', 'returns_lag_5', 'returns_lag_10'\n",
    "]\n",
    "\n",
    "print(f\"特征数量: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48099ce1",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e498929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后: (484153, 37)\n",
      "X shape: (484153, 25)\n",
      "y shape: (484153,)\n",
      "y range: [-1.0000, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "# 清洗数据\n",
    "train_clean = train_featured.dropna().reset_index(drop=True)\n",
    "print(f\"清洗后: {train_clean.shape}\")\n",
    "\n",
    "# 特征标准化\n",
    "feature_scaler = StandardScaler()\n",
    "X = feature_scaler.fit_transform(train_clean[feature_cols])\n",
    "\n",
    "# Target 使用 MinMaxScaler (论文中提到的)\n",
    "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y = target_scaler.fit_transform(train_clean[['Target']]).flatten()\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y range: [{y.min():.4f}, {y.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3643743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "窗口化后 X: (484147, 150)\n",
      "窗口化后 y: (484147,)\n",
      "每个样本特征数: 150\n"
     ]
    }
   ],
   "source": [
    "# 创建滑动窗口序列 (论文使用 window=6)\n",
    "WINDOW_SIZE = 6\n",
    "\n",
    "def create_window_data(X, y, window_size):\n",
    "    \"\"\"将数据转换为窗口格式用于MLP\"\"\"\n",
    "    X_windowed = []\n",
    "    y_windowed = []\n",
    "    \n",
    "    for i in range(window_size, len(X)):\n",
    "        # 将窗口内的所有特征展平\n",
    "        window_features = X[i-window_size:i].flatten()\n",
    "        X_windowed.append(window_features)\n",
    "        y_windowed.append(y[i])\n",
    "    \n",
    "    return np.array(X_windowed), np.array(y_windowed)\n",
    "\n",
    "X_windowed, y_windowed = create_window_data(X, y, WINDOW_SIZE)\n",
    "print(f\"窗口化后 X: {X_windowed.shape}\")\n",
    "print(f\"窗口化后 y: {y_windowed.shape}\")\n",
    "print(f\"每个样本特征数: {X_windowed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4fda20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: (338902, 150)\n",
      "验证集: (145245, 150)\n",
      "\n",
      "Batches - Train: 2648, Val: 1135\n"
     ]
    }
   ],
   "source": [
    "# 时序分割 (论文使用 70:30)\n",
    "train_size = int(len(X_windowed) * 0.7)\n",
    "\n",
    "X_train = X_windowed[:train_size]\n",
    "y_train = y_windowed[:train_size]\n",
    "X_val = X_windowed[train_size:]\n",
    "y_val = y_windowed[train_size:]\n",
    "\n",
    "print(f\"训练集: {X_train.shape}\")\n",
    "print(f\"验证集: {X_val.shape}\")\n",
    "\n",
    "# 转为 Tensor\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "X_val_t = torch.FloatTensor(X_val)\n",
    "y_val_t = torch.FloatTensor(y_val).unsqueeze(1)\n",
    "\n",
    "# DataLoader\n",
    "BATCH_SIZE = 128\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nBatches - Train: {len(train_loader)}, Val: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ada61d",
   "metadata": {},
   "source": [
    "## 超参数调优\n",
    "\n",
    "使用网格搜索优化以下参数:\n",
    "- 窗口大小 (Window Size)\n",
    "- 隐藏层结构\n",
    "- Dropout 比例\n",
    "- 学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6eecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "超参数搜索空间:\n",
      "  window_size: [6, 10, 15, 20]\n",
      "  hidden_sizes: [[512, 256, 128], [256, 128, 64], [512, 256, 128, 64], [256, 128, 64, 32]]\n",
      "  dropout: [0.1, 0.2, 0.3]\n",
      "  learning_rate: [0.001, 0.0005, 0.0001]\n",
      "  batch_size: [64, 128, 256]\n"
     ]
    }
   ],
   "source": [
    "# 超参数搜索空间\n",
    "param_grid = {\n",
    "    'window_size': [6, 10, 15, 20],\n",
    "    'hidden_sizes': [\n",
    "        [512, 256, 128],\n",
    "        [256, 128, 64],\n",
    "        [512, 256, 128, 64],\n",
    "        [256, 128, 64, 32],\n",
    "    ],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [64, 128, 256],\n",
    "}\n",
    "\n",
    "print(\"超参数搜索空间:\")\n",
    "for k, v in param_grid.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "035f1425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练函数已定义\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import time\n",
    "\n",
    "def train_and_evaluate(X, y, window_size, hidden_sizes, dropout, lr, batch_size, epochs=50, patience=10):\n",
    "    \"\"\"训练并评估模型，返回验证集相关系数\"\"\"\n",
    "    set_seed(42)\n",
    "    \n",
    "    # 创建窗口数据\n",
    "    X_w, y_w = create_window_data(X, y, window_size)\n",
    "    \n",
    "    # 分割\n",
    "    train_size = int(len(X_w) * 0.7)\n",
    "    X_tr, y_tr = X_w[:train_size], y_w[:train_size]\n",
    "    X_va, y_va = X_w[train_size:], y_w[train_size:]\n",
    "    \n",
    "    # Tensor\n",
    "    X_tr_t = torch.FloatTensor(X_tr)\n",
    "    y_tr_t = torch.FloatTensor(y_tr).unsqueeze(1)\n",
    "    X_va_t = torch.FloatTensor(X_va)\n",
    "    y_va_t = torch.FloatTensor(y_va).unsqueeze(1)\n",
    "    \n",
    "    # DataLoader\n",
    "    train_ds = TensorDataset(X_tr_t, y_tr_t)\n",
    "    val_ds = TensorDataset(X_va_t, y_va_t)\n",
    "    train_ld = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_ld = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 模型\n",
    "    model = CryptoMLP(\n",
    "        input_size=X_tr.shape[1],\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience_cnt = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # 训练\n",
    "        model.train()\n",
    "        for X_b, y_b in train_ld:\n",
    "            X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(X_b), y_b)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 验证\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_b, y_b in val_ld:\n",
    "                X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "                val_loss += criterion(model(X_b), y_b).item()\n",
    "        val_loss /= len(val_ld)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                break\n",
    "    \n",
    "    # 用最佳模型计算相关系数\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model(X_va_t.to(device)).cpu().numpy().flatten()\n",
    "    \n",
    "    corr = np.corrcoef(y_va, val_pred)[0, 1]\n",
    "    pred_std = np.std(val_pred)\n",
    "    \n",
    "    # 清理 GPU 内存\n",
    "    del model, optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return corr, pred_std, best_val_loss\n",
    "\n",
    "print(\"训练函数已定义\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e3a4918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总组合数: 432\n",
      "采样测试: 20 个组合\n",
      "\n",
      "[1/20] window=20, hidden=[512, 256, 128], dropout=0.1, lr=0.0005, batch=64\n",
      "    -> Corr: nan, Std: 0.0000, Loss: 0.000042 (388.8s)\n",
      "[2/20] window=6, hidden=[512, 256, 128, 64], dropout=0.1, lr=0.0005, batch=64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     corr, pred_std, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     32\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_size\u001b[39m\u001b[38;5;124m'\u001b[39m: ws,\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(hs),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: elapsed\n\u001b[0;32m     42\u001b[0m     })\n",
      "Cell \u001b[1;32mIn[20], line 51\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(X, y, window_size, hidden_sizes, dropout, lr, batch_size, epochs, patience)\u001b[0m\n\u001b[0;32m     49\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(model(X_b), y_b)\n\u001b[0;32m     50\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 51\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     53\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:30\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\6117a\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:114\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_grads], _) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_grads, device)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    112\u001b[0m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[0;32m    113\u001b[0m     ):\n\u001b[1;32m--> 114\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    117\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 执行超参数搜索 (随机搜索，限制组合数量)\n",
    "import random\n",
    "\n",
    "# 生成所有可能的参数组合\n",
    "all_combinations = list(product(\n",
    "    param_grid['window_size'],\n",
    "    param_grid['hidden_sizes'],\n",
    "    param_grid['dropout'],\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['batch_size']\n",
    "))\n",
    "\n",
    "# 随机采样 20 个组合进行测试\n",
    "random.seed(42)\n",
    "n_trials = 20\n",
    "sampled_combinations = random.sample(all_combinations, min(n_trials, len(all_combinations)))\n",
    "\n",
    "print(f\"总组合数: {len(all_combinations)}\")\n",
    "print(f\"采样测试: {len(sampled_combinations)} 个组合\\n\")\n",
    "\n",
    "# 搜索结果\n",
    "results = []\n",
    "\n",
    "for i, (ws, hs, dp, lr, bs) in enumerate(sampled_combinations):\n",
    "    print(f\"[{i+1}/{len(sampled_combinations)}] window={ws}, hidden={hs}, dropout={dp}, lr={lr}, batch={bs}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        corr, pred_std, val_loss = train_and_evaluate(X, y, ws, hs, dp, lr, bs)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        results.append({\n",
    "            'window_size': ws,\n",
    "            'hidden_sizes': str(hs),\n",
    "            'dropout': dp,\n",
    "            'learning_rate': lr,\n",
    "            'batch_size': bs,\n",
    "            'correlation': corr,\n",
    "            'pred_std': pred_std,\n",
    "            'val_loss': val_loss,\n",
    "            'time': elapsed\n",
    "        })\n",
    "        \n",
    "        print(f\"    -> Corr: {corr:.4f}, Std: {pred_std:.4f}, Loss: {val_loss:.6f} ({elapsed:.1f}s)\")\n",
    "    except Exception as e:\n",
    "        print(f\"    -> Error: {e}\")\n",
    "\n",
    "print(\"\\n✅ 超参数搜索完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看最佳参数\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('correlation', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"超参数搜索结果 (按相关系数排序)\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"最佳参数:\")\n",
    "print(\"=\" * 80)\n",
    "best_params = results_df.iloc[0]\n",
    "print(f\"Window Size: {best_params['window_size']}\")\n",
    "print(f\"Hidden Sizes: {best_params['hidden_sizes']}\")\n",
    "print(f\"Dropout: {best_params['dropout']}\")\n",
    "print(f\"Learning Rate: {best_params['learning_rate']}\")\n",
    "print(f\"Batch Size: {best_params['batch_size']}\")\n",
    "print(f\"Correlation: {best_params['correlation']:.4f}\")\n",
    "print(f\"Pred Std: {best_params['pred_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c737a",
   "metadata": {},
   "source": [
    "## 使用最佳参数训练最终模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取最佳参数\n",
    "BEST_WINDOW_SIZE = int(best_params['window_size'])\n",
    "BEST_HIDDEN_SIZES = eval(best_params['hidden_sizes'])  # 从字符串转回列表\n",
    "BEST_DROPOUT = float(best_params['dropout'])\n",
    "BEST_LR = float(best_params['learning_rate'])\n",
    "BEST_BATCH_SIZE = int(best_params['batch_size'])\n",
    "\n",
    "print(\"最佳超参数:\")\n",
    "print(f\"  WINDOW_SIZE = {BEST_WINDOW_SIZE}\")\n",
    "print(f\"  HIDDEN_SIZES = {BEST_HIDDEN_SIZES}\")\n",
    "print(f\"  DROPOUT = {BEST_DROPOUT}\")\n",
    "print(f\"  LEARNING_RATE = {BEST_LR}\")\n",
    "print(f\"  BATCH_SIZE = {BEST_BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用最佳参数重新创建数据\n",
    "set_seed(42)\n",
    "\n",
    "X_windowed_best, y_windowed_best = create_window_data(X, y, BEST_WINDOW_SIZE)\n",
    "\n",
    "train_size = int(len(X_windowed_best) * 0.8)  # 使用更多数据训练\n",
    "\n",
    "X_train = X_windowed_best[:train_size]\n",
    "y_train = y_windowed_best[:train_size]\n",
    "X_val = X_windowed_best[train_size:]\n",
    "y_val = y_windowed_best[train_size:]\n",
    "\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "X_val_t = torch.FloatTensor(X_val)\n",
    "y_val_t = torch.FloatTensor(y_val).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BEST_BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"训练集: {X_train.shape}\")\n",
    "print(f\"验证集: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98103ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建最终模型\n",
    "model_final = CryptoMLP(\n",
    "    input_size=X_train.shape[1],\n",
    "    hidden_sizes=BEST_HIDDEN_SIZES,\n",
    "    dropout=BEST_DROPOUT\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model_final.parameters(), lr=BEST_LR, weight_decay=1e-4)\n",
    "\n",
    "EPOCHS = 150\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=30, T_mult=2)\n",
    "\n",
    "print(model_final)\n",
    "print(f\"\\n参数量: {sum(p.numel() for p in model_final.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练最终模型\n",
    "best_val_loss = float('inf')\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"开始训练最终模型...\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 训练\n",
    "    model_final.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model_final(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_final.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # 验证\n",
    "    model_final.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            output = model_final(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(output.cpu().numpy().flatten())\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    pred_std = np.std(val_preds)\n",
    "    corr = np.corrcoef(y_val, val_preds)[0, 1]\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - Train: {train_loss:.6f} - Val: {val_loss:.6f} - Corr: {corr:.4f} - Std: {pred_std:.4f} - LR: {current_lr:.6f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model_final.state_dict(), '../models/dnn_best.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "print(\"\\n✅ 训练完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d975bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练曲线\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses[-50:], label='Train')\n",
    "plt.plot(val_losses[-50:], label='Val')\n",
    "plt.xlabel('Epoch (last 50)')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History (Zoomed)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型并评估\n",
    "model_final.load_state_dict(torch.load('../models/dnn_best.pth'))\n",
    "model_final.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_pred_scaled = model_final(X_val_t.to(device)).cpu().numpy()\n",
    "\n",
    "val_pred = target_scaler.inverse_transform(val_pred_scaled).flatten()\n",
    "y_val_orig = target_scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_val_orig, val_pred))\n",
    "r2 = r2_score(y_val_orig, val_pred)\n",
    "corr = np.corrcoef(y_val_orig, val_pred)[0, 1]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"最终模型验证集评估\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"R²: {r2:.6f}\")\n",
    "print(f\"Correlation: {corr:.6f}\")\n",
    "print(f\"\\n预测统计:\")\n",
    "print(f\"  Mean: {val_pred.mean():.6f}\")\n",
    "print(f\"  Std: {val_pred.std():.6f}\")\n",
    "print(f\"  Target Std: {y_val_orig.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d4b15",
   "metadata": {},
   "source": [
    "## 测试集预测 (使用最佳模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备测试数据\n",
    "train_tail = train_clean.tail(BEST_WINDOW_SIZE + 100).copy()\n",
    "test_with_history = pd.concat([train_tail, test_featured], ignore_index=True)\n",
    "test_with_history = test_with_history.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# 标准化\n",
    "X_test_scaled = feature_scaler.transform(test_with_history[feature_cols])\n",
    "\n",
    "# 创建窗口\n",
    "X_test_windowed = []\n",
    "for i in range(BEST_WINDOW_SIZE, len(X_test_scaled)):\n",
    "    window_features = X_test_scaled[i-BEST_WINDOW_SIZE:i].flatten()\n",
    "    X_test_windowed.append(window_features)\n",
    "X_test_windowed = np.array(X_test_windowed)\n",
    "\n",
    "# 只取测试集部分\n",
    "n_test = len(test_df)\n",
    "X_test_windowed = X_test_windowed[-n_test:]\n",
    "\n",
    "print(f\"测试数据形状: {X_test_windowed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "X_test_t = torch.FloatTensor(X_test_windowed).to(device)\n",
    "\n",
    "model_final.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred_scaled = model_final(X_test_t).cpu().numpy()\n",
    "\n",
    "# 反归一化\n",
    "test_predictions = target_scaler.inverse_transform(test_pred_scaled).flatten()\n",
    "\n",
    "print(f\"预测数量: {len(test_predictions)}\")\n",
    "print(f\"预测均值: {test_predictions.mean():.6f}\")\n",
    "print(f\"预测标准差: {test_predictions.std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef21c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成提交文件\n",
    "submission_df = pd.DataFrame({\n",
    "    'Timestamp': test_df['Timestamp'].values[:len(test_predictions)],\n",
    "    'Prediction': test_predictions\n",
    "})\n",
    "\n",
    "submission_file = Path('../submissions/dnn_tuned_submission.csv')\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"✅ 提交文件已保存: {submission_file}\")\n",
    "print(f\"\\n预览:\")\n",
    "print(submission_df.head(10))\n",
    "print(f\"\\n统计:\")\n",
    "print(submission_df['Prediction'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ada69",
   "metadata": {},
   "source": [
    "## 定义 MLP 模型\n",
    "\n",
    "论文架构: Input -> 3 Hidden Layers -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da66365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CryptoMLP(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=150, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "参数量: 80,769\n"
     ]
    }
   ],
   "source": [
    "class CryptoMLP(nn.Module):\n",
    "    \"\"\"多层感知器 (DNN) 用于加密货币预测\n",
    "    \n",
    "    基于论文架构:\n",
    "    - Input: (window_size * n_features)\n",
    "    - 3个隐藏层，使用 ReLU 激活\n",
    "    - Output: 1 (预测值)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_sizes=[256, 128, 64], dropout=0.2):\n",
    "        super(CryptoMLP, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # 隐藏层\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # 输出层\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # 权重初始化\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# 创建模型\n",
    "input_size = X_train.shape[1]  # window_size * n_features\n",
    "model = CryptoMLP(\n",
    "    input_size=input_size,\n",
    "    hidden_sizes=[256, 128, 64],\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\n参数量: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c85d2",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd765d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 损失函数和优化器 (论文使用 Adam, lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# 训练参数\n",
    "EPOCHS = 10\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"开始训练...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f26d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train: 0.000209 - Val: 0.000042 - Pred Std: 0.0001\n",
      "\n",
      "Early stopping at epoch 4\n",
      "\n",
      "✅ 训练完成!\n",
      "\n",
      "Early stopping at epoch 4\n",
      "\n",
      "✅ 训练完成!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    # 训练\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # 验证\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(output.cpu().numpy().flatten())\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # 监控预测标准差\n",
    "    pred_std = np.std(val_preds)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - Train: {train_loss:.6f} - Val: {val_loss:.6f} - Pred Std: {pred_std:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), '../models/dnn_best.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "print(\"\\n✅ 训练完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e56da80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAAHWCAYAAAAhEvvEAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVJFJREFUeJzt3QeYVNX5x/F3+wJSpSwoAirSexPEoIKCEAOIQZBICYoaUBCNgpGmRCKIFCUisUZREAsxCiiCSASko9IM8icgUpbO0rbN/T/vkTvOzM4uuzC7M3v4fp7nOjv3nrlzZ86szG9Pi3IcxxEAAAAAgDWiw30BAAAAAIDQIugBAAAAgGUIegAAAABgGYIeAAAAAFiGoAcAAAAAliHoAQAAAIBlCHoAAAAAYBmCHgAAAABYhqAHAAAAAJYh6AEAkM9Gjx4tUVFR5/XYN954wzz2f//7nxQGeq36egEA4UXQAwCEnBtO3C0xMVEqVaok7du3l6lTp0pKSkq2YahChQpy6tSpLMerVq0qv/3tb/32ueefOHFittewZs2abK9Tz+l7ndlteq6LkVsnBw8eDHo8WJ2cj3feeUcmT558wecBAPwq1udnAABC6qmnnpJq1apJenq67Nu3T5YsWSJDhgyR559/Xj7++GOpX79+lsckJyfLSy+9JI888kiun2fChAnywAMPSNGiRfN0fRouTpw44b0/b948effdd2XSpElStmxZ7/5WrVrJhXjyySdl2LBh5/XYu+++W3r06CEJCQlSGJw+fVpiY2PzHPQ2btxoPhsAgNAg6AEA8s2tt94qTZs29d4fPny4LF682LQC/e53v5MtW7ZIkSJF/B7TsGFDE9z+9Kc/ZTkWjJbfsGGDTJ8+XYYOHZqn6+vSpYvffQ2jGvR0v7ZWZefkyZNSrFixXD+PBp+8hh9XTEyM2QoLbb2NBBkZGeLxeCQ+Pj7clwIAYUHXTQBAgbrppptkxIgRsnPnTnn77bezHB85cqTs37/ftOrlxnXXXWfOOX78eNOaFGp9+/aVSy65RLZv3y4dO3aU4sWLS69evcyx//znP/L73/9errjiCtPiVrlyZXn44YezXEewMXp6f9CgQTJ37lypW7eueXydOnVkwYIF5xyj53aZ/Prrr6V58+YmXF155ZXyz3/+M8v1f/fdd9KmTRsTmi+//HIZO3asvP766/k27i9wjJ5209WWOr1mfY3ly5eXm2++WdatW2eO33DDDfLpp5+az4PbVdY3ZGsLb//+/U2XXn2dDRo0kDfffNPvOfV16OOee+4500p71VVXmedatWqVCeSDBw/Ocp27d+82AXrcuHEhfw8AIBLQogcAKHDaHfGJJ56Qzz//XO69916/Y9dff703uGl3zNy06mmw+M1vfmPCYV5b9XLbOqTjC1u3bm3ChNtFdM6cOWY8oV7npZdeaoLFCy+8YEKEHjsXDWoffvihab3UAKnjF7t16ya7du0y58vJjz/+KHfccYcJQX369JHXXnvNhNImTZqYwKh+/vlnufHGG00I0tZUDT2vvPJKnruBHj58OOh+bTE7l/vvv1/ef/99E2pr164thw4dMq9bW3MbN24sf/nLX+TYsWPmPdMus0qDtdLArEFQX6s+XrsB6/uqr/Po0aNZApwG2DNnzsiAAQPMa9QA3rVrV5k9e7bpLuzbMqott47jeEM7AFjHAQAgxF5//XVH/4lZvXp1tmVKlizpNGrUyHt/1KhR5jEHDhxwvvrqK/Pz888/7z1epUoVp1OnTn7n0DIDBw40P994441OUlKSc+rUqVxfQ6AJEyaYx+zYscO7r0+fPmbfsGHDspR3n8vXuHHjnKioKGfnzp1ZXlvgtcfHxzs//vijd9+3335r9r/wwgvefe7r8L0mfS9039KlS737kpOTnYSEBOeRRx7x7nvwwQfNtaxfv96779ChQ06ZMmWynDMY97pz2oLViT7Ot57dOsqOnkNfU6DJkyeb87399tvefWlpaU7Lli2dSy65xDl+/LjZp69Dy5UoUcK8D74+++wzc2z+/Pl+++vXr++0adMmx+sCgMKMrpsAgLDQVptgs28qbZ3Tlqi8dMfUVj0dY6dj9fKDttoF8m1t1HF7OjulTtyieWf9+vXnPGe7du1MN0OXTk5TokQJ+b//+79zPlZbx7T101WuXDmpUaOG32O1G2jLli3NOEZXmTJl8tyK9cEHH8jChQuzbNqd8lxKlSolK1eulD179khe6eQ4SUlJ0rNnT+++uLg4eeihh8wkOl999ZVfeW0N1fch8D3WGV9nzpzp3acTv2iX1j/84Q95viYAKCwIegCAsNAv6tpdMVTB7XzCYW7pRCo6vi2QdrHUboQanjS4asjQ8XBKuyOei3YtDFS6dGk5cuRISB6r496uvvrqLOWC7TvXe6uBKXDLzcQrWh8arHT8oo4n1HrNTZB1r7969eoSHe3/daVWrVre4760a2cgfawGWx0L6S7boaFPr13HVwKArQh6AIACp+OxNAjlFDg0XOj4rLwEt1GjRplw+PLLL4fwasWM9woMG5mZmWZSEZ1I5PHHHzdBQlu53DX3cjN+LbvZNH/pAZl/jy1I3bt3N8FOxy5qy5rOqKpjCOfPnx/y58puPGfv3r3NHxa0jvT90eUcdDKbkiVLhvwaACBSEPQAAAXurbfeMrc6wUlO3Fa93AY3bU3TcPjss8/mywycvr7//nv573//axZr16DXuXNnbzfBSFGlShUzkUmgYPvyU8WKFc2EMxq0duzYYSaa+etf/+o9Hjgjqe/1b9u2LUto3rp1q/d4buispo0aNTIteTpTqrbE6oRAAGAzgh4AoEDpOnpPP/206WZ3rrFivsFNZ1PMDTcczpgxQ/KT26Lm24KmP0+ZMkUihQbpFStWmHUGfWfQ9B2vlp+01TOwC6sur6BhODU11btPZwMN1tVVl7PQutRZM31nQNXWQe0q63aTzQ0NdjrLqy6/oEFT13gEAJuxvAIAIN9o9zxtfdEv57o2noY87d6oLTEff/xxrsZ4aXdMHXuXW/rlX7fAiTpCrWbNmmYilUcffdQsY6CTqOikJbkZX1dQHnvsMbNWoXYxffDBB73LK+j4Pg182bWkhYpOtqNjG3UZCF3/TsPZF198IatXrzYtoS5dEkLDnC6N0axZM1PutttuM8skaGuujoNcu3atWV9Pl2pYtmyZCWw5jfEMdNddd5n346OPPjIT6+ikLgBgM4IeACDf6OLnKj4+3kxYUq9ePfMFvV+/frn+kq4tenkNbtqql5dweD40KPz73/82M0DqotsaWnXNNl3vTUNNJNAJUL788ktzjc8884yZLGbgwIEm8Om+3ATtC6HrDWqXTW1J0/UCtQumjsv8+9//7jeLqZbRVkddB0/X0tM/BGjQ0zF3S5YskWHDhplF0o8fP25mFtVyGv7yQmcIveWWW8xMnnTbBHAxiNI1FsJ9EQAAoOAMGTLEtJTpBCXZTepiIw3iOrayoMcoAkA4MEYPAACLBU5Kc+jQITMZTuvWrS+qkLd3714zQyqteQAuFnTdBADAYrpgunZ/1bXndJzkq6++arpAjhgxQi4GOsunjunTsYna3fa+++4L9yUBQIEg6AEAYDGduVInMNFZSHXylcaNG5uwp+sUXgx0bKeOCdUJaHScX1JSUrgvCQAKBGP0AAAAAMAyjNEDAAAAAMsQ9AAAAADAMozRi3C65tCePXvMelP5vbAtAAAAgMilK+OlpKRIpUqVJDo65zY7gl6E05CnC94CAAAAgPrpp5/k8ssvl5wQ9CKctuS5lVmiRImwty4eOHBAypUrd86/IKDwoF7tQ53aiXq1D3VqH+rUTp4I+g6sy+NoI5CbEXJC0ItwbndNDXmREPTOnDljriPcH3KEDvVqH+rUTtSrfahT+1CndvJE4Hfg3AzpiowrBQAAAACEDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwTGy4LwCFx+BZG2TrnqNSouh2KZoQK8XiY6VoQowUjY/55WezxZh9er+Iu9+vjP4cK4lx0RIVFRXeFwQAAABYiqCHXNtx8KRsO3haRHS7MJrxinnDYIxPSIwNuO8fEIslxEiRuBgplvDrPhMiz95PiCVAAgAAAAQ95NozXevKjj0HJK7IJXI63SOn0jPlVGqGnEzLlNNpv9zq/VN6m5YpJ9My5PTZ21Opv+w7nZ5pzuU4IidSM8x2IIR1EO0bIL1h0Dck/nJr7sfHBJQ7GzJ9HueeiwAJAACAwoSgh1yre1lJKR+XKuXLl5fo6PMb3pnpcUzYcwOhCYFng2F2odH87C2XISdTtYzvYzPkTLrHnN/jiKSkZphNUlJDVrsx0VF+4c90R4375davZVJDYpxPy6T3vk/L5Nlj+pj4GFogAQAAEHoEPRQoDUyXJMSaLZQ0QP4aBjPlpLdl8WxYTM0wAVNDYmBo9P7shkyfMqkZHu/5U85kmE0kdAEy1hsgsw+NwVomvV1bvffdFslfHh8fyzxLAAAAFzOCHqwJkMUT48wWShmZbhdV/9Do7gvWPTW70OhtwUzNlLTMXwJkhseR42cyzBZKcTEaIH26oCbEBoxt/DUkJsbFiCf1tFS4NFWKJcT5dG11u8D+GizjYgiQAAAAhQFBD8jpFyQmWkroFuIAma4B0rdLatDQeLYLa3ZlArq8arn0TOfs+R05djrdbLn30zlLaFfTX7qt+ndBLWZaJP27qfq1TAbMuurtynr2XPo+AwAAIHQIekAYaMtYySK6hTZApmV4soxfNGMa04O0LrpjIFMz5PDxk+KJjs06kc7ZMtryaM6f6ZG0Ux45KnkJkOemXU0DZ1/9pdtq1m6qRbILjb6tl/ozARIAAFzECHqARTQw6VayaO4DpMfjkeTk5Bwn2dEAGdgl9dfWRd/ZVt0y/uMkvS2TZ7u3ukFUxz6659ftyKnQBkidLfXXbqs5jW3UABk4/tG/y6vbeqnHtaswAABAJCPoAchlgIyXUkVD92Y5jmNaCP27pOZyRtaA7qzebrBn75/Nj2YyndSMtJDXcGJc9K9rOLpdUANDo1+31axrRf7a5fXssbgYiSZAAgCAECHoAQiLqKgoSYjVNQpjpHSx+JAGSA14/rOt+oTGgElyfu2mGmxGVv+JdHT9R6XLeZxJT5PDJyWktPXwlzAY0D3Vp0tqsNAYuFZkkbgoSUlJE0/CmVwvhRKVx0bKPLdp5vn8uX9Afl+7flbz6/x5ObW2vuvETQmn0yU6KpfjWvP63kTZ/z7+cu48Xks+NeI7Hv1jlEdS0zMlKvrs/2AuYu7/Y8PNkfO/EP09NctIpWWc91JUkfVeRAb9tz2cPJ5fvlcUNgQ9AFbRL5M6k6huZfIhQPqGRt+Jc7ILjW4Zv1ZLb4vkLzO4uv9+6ZcD3Q6FOEACAIALU6V0gnz554pSmBD0ACCPAfLSEL5jGiC1hdAbGrNMnHN2Qp2ASXb8u61mbbVMzcjMdauFk89/Wc37+fP4AAAAkAVBDwDCHCC1S6ZucklozpmbCXYuVnkOqXkMnU4+XkumxyMHkg9IufLlclWveb92J2LCeF7On9dudvlZp7+c38lTnR46cFDKlitb4L+ree1KG5LnLPBnPPu8BfjE+v/fAwcOSPly4fn/bxiqNWwKul4PHjgghQ1BDwBw0cjzOLF8/SKRt5PrXD2xMVFmeRYCvB30y+OZhBgpnhhHnVpUpzreWv94x++pPTyeX/7fW9gUvisGAAAAAOSIoAcAAAAAlomIoDdt2jSpWrWqJCYmSosWLWTVqlU5lp8zZ47UrFnTlK9Xr57MmzcvS//4kSNHSsWKFaVIkSLSrl072bZtm1+Zw4cPS69evaREiRJSqlQp6d+/v5w4ccJ7fMmSJdK5c2dzjmLFiknDhg1l5syZ+XItAAAAAGBV0Js9e7YMHTpURo0aJevWrZMGDRpI+/btzUQCwSxfvlx69uxpgtn69eulS5cuZtu4caO3zPjx42Xq1Kkyffp0WblypQlqes4zZ854y2jI27RpkyxcuFA++eQTWbp0qQwYMMDveerXry8ffPCBfPfdd9KvXz/p3bu3KRvqawEAAACAkHLCrHnz5s7AgQO99zMzM51KlSo548aNC1q+e/fuTqdOnfz2tWjRwrnvvvvMzx6Px0lKSnImTJjgPX706FEnISHBeffdd839zZs365RYzurVq71l5s+f70RFRTk///xzttfasWNHp1+/fiG9lnM5duyYuVa9DTetm71795pb2IN6tQ91aifq1T7UqX2oUztlRtB34Lxkg7DOupmWliZr166V4cOHe/fpDEXavXHFihVBH6P7tQXQl7aQzZ071/y8Y8cO2bdvnzmHq2TJkqZLqD62R48e5la7azZt2tRbRsvrc2urW9euXYM+97Fjx6RWrVohvZZAqampZnMdP37cO4uTbuGkz69dUcN9HQgt6tU+1KmdqFf7UKf2oU7t5Img78B5uYawBr2DBw9KZmamVKhQwW+/3t+6dWvQx2hwClZe97vH3X05ldH1pXzFxsZKmTJlvGUCvffee7J69Wp5+eWXQ3otgcaNGydjxozJsl/XZAl3d0/9YGnY1Q86Uwbbg3q1D3VqJ+rVPtSpfahTO3ki6DtwSkpKrsuyjl4ufPnll2aM3j/+8Q+pU6eO5Cdt3fRtJdQWvcqVK0u5cuXMxDHh/pDrGlR6LeH+kCN0qFf7UKd2ol7tQ53ahzq1kyeCvgPrBJCFIuiVLVtWYmJiZP/+/X779X5SUlLQx+j+nMq7t7pPZ7r0LaMzZ7plAid7ycjIMDNxBj7vV199JbfddptMmjTJTMYS6msJlJCQYLZA+qEK9wdL6Yc8Uq4FoUO92oc6tRP1ah/q1D7UqZ2iIuQ7cF6eP6xXGh8fL02aNJFFixb5JWa937Jly6CP0f2+5ZXOnOmWr1atmglYvmW0VUzH3rll9Pbo0aNmfKBr8eLF5rl1/JzvEgudOnWSZ5991m9GzlBeCwAAAACEWti7bmo3xT59+piJUZo3by6TJ0+WkydPmq6SSlvRLrvsMjN2TQ0ePFjatGkjEydONCFs1qxZsmbNGpkxY4Y3bQ8ZMkTGjh0r1atXN2FrxIgRUqlSJbP0gdIJVTp06CD33nuvWfYgPT1dBg0aZCZH0XJud83f/va35vm6devmHVOn4VTH8oXqWgAAAAAg5JwI8MILLzhXXHGFEx8fb5Zb+Oabb7zH2rRp4/Tp08ev/Hvvvedcc801pnydOnWcTz/91O+4LmswYsQIp0KFCmYpg7Zt2zo//PCDX5lDhw45PXv2dC655BKnRIkSZtmElJQU73F9Tn17Aje9nlBfS05YXgEX05TBCA3q1E7Uq32oU/tQp3bKjKDvSnnJBlH6n9DHR4SKdvXUJRl0pp9ImIxFxzbqjKXh7p+M0KFe7UOd2ol6tQ91ah/q1E6eCPoOnJdswLd1AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACwT9qA3bdo0qVq1qiQmJkqLFi1k1apVOZafM2eO1KxZ05SvV6+ezJs3z++44zgycuRIqVixohQpUkTatWsn27Zt8ytz+PBh6dWrl5QoUUJKlSol/fv3lxMnTniPnzlzRvr27WvOHxsbK126dMlyHXo8Kioqy1anTh1vmdGjR2c5rtcOAAAAANYGvdmzZ8vQoUNl1KhRsm7dOmnQoIG0b99ekpOTg5Zfvny59OzZ0wSz9evXmwCm28aNG71lxo8fL1OnTpXp06fLypUrpVixYuacGt5cGvI2bdokCxculE8++USWLl0qAwYM8B7PzMw0IfGhhx4yQTGYKVOmyN69e73bTz/9JGXKlJHf//73fuU0+PmW+/rrr0PwzgEAAABA9qIcbQILE23Ba9asmbz44ovmvsfjkcqVK8uDDz4ow4YNy1L+zjvvlJMnT5pw5rr22mulYcOGJtjpS6lUqZI88sgj8uijj5rjx44dkwoVKsgbb7whPXr0kC1btkjt2rVl9erV0rRpU1NmwYIF0rFjR9m9e7d5fGDL3dGjR2Xu3Lk5vhY9fvvtt8uOHTukSpUq3hY93b9hw4Zcvyepqalmcx0/fty8J0eOHDEtkOGk9XPgwAEpV66cREeHvTEYIUK92oc6tRP1ah/q1D7UqZ08EfQdWLNB6dKlTcY5VzaIlTBJS0uTtWvXyvDhw7379I3TFrQVK1YEfYzu1xZAX9pa54YwDVn79u3za4UrWbKkCZT6WA16eqvdNd2Qp7S8Pre2AHbt2vW8Xs+rr75qzuOGPJd2G9XwqF1NW7ZsKePGjZMrrrgi2/Po8TFjxmTZrx8u31bJcH3I9UOlgTrcH3KEDvVqH+rUTtSrfahT+1CndvJE0HfglJSUXJcNW9A7ePCg6SKprW2+9P7WrVuDPkZDXLDyut897u7LqUz58uX9jus4PO126ZbJqz179sj8+fPlnXfe8duvAVNbEmvUqGG6bWqAu/76601X0+LFiwc9lwZf3zDrtujpXxAioUVPxxlGwl8zEDrUq32oUztRr/ahTu1DndrJE0HfgbXxKOKDnk3efPNN00oYOGnLrbfe6v25fv36Jvhpi997771nxhkGk5CQYLZA+qEK9wdL6Yc8Uq4FoUO92oc6tRP1ah/q1D7UqZ2iIuQ7cF6eP2xXWrZsWYmJiZH9+/f77df7SUlJQR+j+3Mq796eq0zgZC8ZGRlmJs7snjcn2oT72muvyd133y3x8fE5ltUweM0118iPP/6Y5+cBAAAAgIgPehqKmjRpIosWLfJrFtX7OpYtGN3vW17pzJlu+WrVqpmw5ltGuz7q2Du3jN7q5Co6PtC1ePFi89za4pZXX331lQlu2bXQ+dIlHLZv326WfgAAAACA/BLWrps6Fq1Pnz5mYpTmzZvL5MmTzaya/fr1M8d79+4tl112mZmgRA0ePFjatGkjEydOlE6dOsmsWbNkzZo1MmPGDG+T6pAhQ2Ts2LFSvXp1E/xGjBhhJkNxu1XWqlVLOnToIPfee6+ZqTM9PV0GDRpkJmrxnXFz8+bNZsIYbenTQY/uzJk6w2fgJCwaEOvWrZvl9enMn7fddpvprqnj+HQZCW3F1CUiAAAAAMDKoKfLJehskrrAuU6EoiFKlzpwJ1PZtWuXXz/UVq1amQlPnnzySXniiSdMmNMZN31D1mOPPWbCoq6Lpy13rVu3Nuf0Hbg4c+ZME+7atm1rzt+tWzez9p4vXW5h586d3vuNGjUyt76rUejsOx988IFZUy8YXa5BQ92hQ4fM4E29lm+++cb8DAAAAABWrqOHc9Oup7pERG7Wyshv2r1VxzfqrKXhHoiK0KFe7UOd2ol6tQ91ah/q1E6eCPoOnJdswLd1AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwTNiD3rRp06Rq1aqSmJgoLVq0kFWrVuVYfs6cOVKzZk1Tvl69ejJv3jy/447jyMiRI6VixYpSpEgRadeunWzbts2vzOHDh6VXr15SokQJKVWqlPTv319OnDjhPX7mzBnp27evOX9sbKx06dIly3UsWbJEoqKismz79u27oNcHAAAAAIU66M2ePVuGDh0qo0aNknXr1kmDBg2kffv2kpycHLT88uXLpWfPniaYrV+/3gQw3TZu3OgtM378eJk6dapMnz5dVq5cKcWKFTPn1PDm0pC3adMmWbhwoXzyySeydOlSGTBggPd4ZmamCYkPPfSQCYo5+eGHH2Tv3r3erXz58uf9+gAAAAAgFKIcbQILE23hatasmbz44ovmvsfjkcqVK8uDDz4ow4YNy1L+zjvvlJMnT5pw5rr22mulYcOGJtjpS6lUqZI88sgj8uijj5rjx44dkwoVKsgbb7whPXr0kC1btkjt2rVl9erV0rRpU1NmwYIF0rFjR9m9e7d5vC9t2Tt69KjMnTs3S4vejTfeKEeOHDGtgqF4fcEcP35cSpYsaV6HtkCGk16/hlQNs9HRYW8MRohQr/ahTu1EvdqHOrUPdWonTwR9B85LNoiVMElLS5O1a9fK8OHDvfv0jdMWtBUrVgR9jO7XFjJf2kLmhrAdO3aYrpO+rXD6Rmjg0sdq0NNbDWZuyFNaXp9bWwC7du2ap9ehITM1NVXq1q0ro0ePluuuu+68X5/Sc+nmW5nuB0y3cNLn1zAd7utAaFGv9qFO7US92oc6tQ91aidPBH0Hzss1hC3oHTx40HSR1NY2X3p/69atQR+jIS5YeXdcnHt7rjK+3SuVjsMrU6ZMlvF1OdExgNqKqIFRg9krr7wiN9xwgwmLjRs3Pq/Xp8aNGydjxozJsv/AgQN+3U/D9cHSvx7oBz3cf81A6FCv9qFO7US92oc6tQ91aidPBH0HTklJifygV9jVqFHDbK5WrVrJ9u3bZdKkSfLWW2+d93m1BdC31VJb9LS7Z7ly5SKi66ZOOKPXEu4POUKHerUPdWon6tU+1Kl9qFM7eSLoO7BO8BjxQa9s2bISExMj+/fv99uv95OSkoI+RvfnVN691X3a4uZbRrtYumUCJ0PJyMgwM3Fm97y51bx5c/n666/P+/WphIQEswXSD1W4P1hKP+SRci0IHerVPtSpnahX+1Cn9qFO7RQVId+B8/L8YbvS+Ph4adKkiSxatMgvLev9li1bBn2M7vctr3TmTLd8tWrVTIjyLaMtYtqd0i2jtzq5io6fcy1evNg8t47luxAbNmzwBszzeX0AAAAAEAph7bqpXRT79Oljxrlpa9jkyZPNrJr9+vUzx3v37i2XXXaZGbemBg8eLG3atJGJEydKp06dZNasWbJmzRqZMWOGN2kPGTJExo4dK9WrVzfBb8SIEWYmTXctvFq1akmHDh3k3nvvNWPs0tPTZdCgQWaiFt8ZNzdv3mwmVNGWPu0LqyFOuS2Deq16/jp16pixczpGTwPj559/nuvXBwAAAADWBT1dLkEnGdEFznUiFA1RutSBO4HJrl27/JondRzcO++8I08++aQ88cQTJszpjJs646XrscceM2FK18XTlrvWrVubc/r2Z505c6YJd23btjXn79atm1l7z5cut7Bz507v/UaNGplbdzUKDYG6jMPPP/8sRYsWlfr168sXX3xhllzI7esDAAAAAOvW0cO5sY4eLqa1YRAa1KmdqFf7UKf2oU7t5Img70p5yQZ8qwMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALBMbLgvAAAAAIAdPB6PpKWliW2vKT09Xc6cOSPR0fnbThYXFycxMTEhORdBDwAAAMAF04C3Y8cOE4xs4jiOeU0pKSkSFRWV789XqlQpSUpKuuDnIugBAAAAuOAwtHfvXtMaVbly5Xxv+Sro15aRkSGxsbH5GvT0eU6dOiXJycnmfsWKFS/ofAQ9AAAAABdEg5CGlEqVKknRokWtejedAgp6qkiRIuZWw1758uUvqBunPVEbAAAAQFhkZmaa2/j4eGrgArlBWccFXgiCHgAAAICQKIgxbLaLCtF7SNADAAAAAMsQ9AAAAAAgRKpWrSqTJ0+WcCPoAQAAALgou0hG5bCNHj36vM67evVqGTBggIQbs24CAAAAuOjs3bvX+/Ps2bNl5MiR8sMPP3j3XXLJJVlm3tQFzc+lXLlyEglo0QMAAABw0UlKSvJuJUuWNK147v2tW7dK8eLFZf78+dK0aVMT+r7++mvZvn27dO7cWSpUqGD2NWvWTL744oscu27qeV955RXp2rWrmVGzevXq8vHHH+f76yPoAQAAAAj94t9pGWHZ9LlDZdiwYTJu3Dj57rvvpH79+nLixAnp2LGjLFq0SNavXy8dOnSQ2267TXbt2pXjecaMGSPdu3c359HH9+rVSw4fPiz5ia6bAAAAAELqdHqm1B75WVje1c1PtZei8aGJOU899ZTcfPPN3gXTL730UmnQoIH3+NNPPy0fffSRaaEbNGhQtufp27ev9OzZ0/z8zDPPyNSpU2XVqlUmKEZUi95PP/0ku3fv9t7XixwyZIjMmDEjlNcGAAAAAGHTtGlTv/vaovfoo49KrVq1pFSpUqb75pYtW87Zoqetga5ixYpJiRIlJDk5WfLTeUXdu+66y8wkc/fdd8u+fftMyq1Tp47MnDnT3NeBjAAAAAAuTkXiYkzLWrieO1Q0lPnSkLdw4UJ57rnn5Oqrr5YiRYrIHXfcIWlpaTmeJ3ASFx235/F4JOKC3saNG6V58+bm5/fee0/q1q0ry5Ytk88//1zuv/9+gh4AAABwEdMgE6ruk5Fk2bJlphumTqzitvD973//k0h0Xl0309PTJSEhwfyss8z87ne/Mz/XrFnTb5pSAAAAALBF9erV5cMPP5QNGzbIt99+a3o65nfLXIEGPe2mOX36dPnPf/5jmi7dQYR79uwxAxQBAAAAwDbPP/+8lC5dWlq1amVm22zfvr00btxYItF5tac+++yzprlywoQJ0qdPH+/MMzrbjNulEwAAAAAKg759+5rNdcMNN3iXafBdrkHXyFu8eLHfYwcOHOh3P7ArZ7DlHo4ePSoRGfT0hR88eFCOHz9uEq1LJ2jRRQABAAAAAIWs6+bp06clNTXVG/J27txpVn//4YcfpHz58qG+RgAAAABAfge9zp07yz//+U9vs2OLFi1k4sSJ0qVLF3nppZfO55QAAAAAgHAGvXXr1sn1119vfn7//felQoUKplVPw5+u8p4X06ZNM31dExMTTWDUxddzMmfOHDO7p5avV6+ezJs3L0sfWF3Hr2LFimZdi3bt2sm2bdv8yhw+fFh69eplFirUhQ779+9vpkZ1nTlzxvTR1fPHxsaaABtIZ9vR9QPLlStnztOyZUv57LPP/MqMHj3aTC3ru+m1AwAAAEDEBb1Tp05J8eLFzc+6dt7tt98u0dHRcu2115rAl1uzZ8+WoUOHyqhRo0x41ElddOaa7FaJX758ufTs2dMEs/Xr15sAppuu6+caP368CZs6K+jKlSvNIod6Tg1vLg15mzZtMjOGfvLJJ7J06VIzvtCVmZlpQuJDDz1kgmIw+hgNeho0165dKzfeeKOZeUevK3CGUl1ywt2+/vrrXL8/AAAAAHBenPNQr149Z8qUKc6uXbucEiVKOMuXLzf716xZ41SoUCHX52nevLkzcOBA7/3MzEynUqVKzrhx44KW7969u9OpUye/fS1atHDuu+8+87PH43GSkpKcCRMmeI8fPXrUSUhIcN59911zf/PmzTrtjbN69Wpvmfnz5ztRUVHOzz//nOU5+/Tp43Tu3DlXr6d27drOmDFjvPdHjRrlNGjQwLkQx44dM9ert+Gm9bN3715zC3tQr/ahTu1EvdqHOrXPxVynp0+fNt+z9dY2Ho/HSUtLM7fhfi/zkg3Oa9ZN7RqpiwM+/PDDctNNN5lui27rXqNGjXJ1jrS0NNMSNnz4cO8+bRXUFrQVK1YEfYzu1xZAX9paN3fuXPPzjh07ZN++fX6tcCVLljRdQvWxPXr0MLfaXbNp06beMlpen1tbAN1V7vNKF0pMSUmRMmXK+O3XbqOVKlUyXU31fRo3bpxcccUV2Z5HJ7nRzaUzm7rnD/dijPr82jU23NeB0KJe7UOd2ol6tQ91ap+LuU7d1+5utnGCLLWQn8/lfo4CP0t5+WydV9C74447pHXr1qYroruGnmrbtm2ug5Iuz6BdJHV8ny+9v3Xr1qCP0RAXrLzud4+7+3IqEzgzqI7D04Dmljkfzz33nBnn1717d+8+DZhvvPGG1KhRw7xXY8aMMWMbtaup2/U1kAZBLRfowIEDft1Pw0E/WMeOHTMfPA3GsAP1ah/q1E7Uq32oU/tczHWanp5uXn9GRobZbOI4jsktSufcyG/6/ul7eejQIYmLi/M7pg1L+Rr0VFJSktl2795t7l9++eUX7WLp77zzjgln//rXv/xC5K233ur9uX79+ib4ValSRd577z0zzjAYbeH0bbXUFr3KlSt7J30JJ/3A6Ydbr+Vi+5+XzahX+1CndqJe7UOd2udirlNtkNAQog0outkoLiB05Rd9//Tzc+mll5pegb4C7+d4nvP9EI8dO9YsqeDOVqktVI888oj85S9/ydUHu2zZshITEyP79+/326/3NUAGo/tzKu/e6j6dddO3TMOGDb1lAid70dSsM3Fm97w5mTVrltxzzz1mNtDsJm5xaZfRa665Rn788cdsyyQkJJgtkL6nkfA/DP2fV6RcC0KHerUPdWon6tU+1Kl9LtY61dfrO9O8bS16UWdfU+Bru+GGG0zO0DXFQ8V9D4N9jvLyuTqvT6CGuRdffFH+9re/mVkmdXvmmWfkhRdekBEjRuTqHPHx8dKkSRNZtGiRX4DU++6Yv0C637e80pkz3fLVqlUzYc23jLaI6dg7t4ze6tp/Oj7QtXjxYvPc2uKWF++++67069fP3Hbq1Omc5TUUb9++3S+EAgAAACh4t912m3To0CHosf/85z8mbH333XcFfl2hcl4tem+++aa88sor8rvf/c6va+Jll10mf/rTn+Svf/1rrs6jXRT79OljJkbRbp+ahE+ePGnCk+rdu7c5p45bU4MHD5Y2bdqYlkQNVtqatmbNGpkxY4Y5rpUxZMgQ09pYvXp1E/w0eOpkKO5aeLVq1TIVeu+995olGLQ/8aBBg8xELVrOtXnzZjNhjLb0aTP0hg0bzH63ZVC7a+q1T5kyxQREd3yfLsugE8CoRx991HyAtLvmnj17zDIS2oqpS0QAAAAACJ/+/ftLt27dzFA0HYbm6/XXXzcZRTNOYZ1c5rxa9DT8BFv4W/fpsdy68847zSQmOounBigNUwsWLPBOprJr1y4ziYmrVatWJmBpsNNJYHSxdp1xs27dut4yjz32mDz44INmXbxmzZqZVjQ9p29/1pkzZ5pr1cljOnbsaCaWccOiS/frDKL//ve/ZcmSJeZn3xlFtbx2+Rw4cKBpoXM3DaMu/dBoqNPJWHSSFu1n+80335h+2wAAAADC57e//a35Xq6TJ/rS/KDDsrShSL/LawjUhhwNfdqTr7CI0jUW8vogbcHSTRcm96UBa9WqVaarJEJDu57qB0tncIqEyVh0fKNOOHOx9Tu3GfVqH+rUTtSrfahT+1zMdaqTsehSZ9qjzjSwaMRIPxWei4krql39clVUG4k+/PBDsySaO/5OW/O0MWfLli0m8GnjUNGiReWzzz4zPRKXL1/unYQyP8boZXkvzzMbnFfXzfHjx5uuk1988YV37JuuT/fTTz/JvHnzzueUAAAAAGyhIe+ZX4dFFagn9ojEF8tV0T/+8Y8yYcIE+eqrr0xoc4OedunU4Vc6FEvbxbQnnzZq6brhOoN+YVht4Lz+1KDj5P773/+aNfN0YhPdbr/9dtm0aZO89dZbob9KAAAAAAixmjVrmuFhr732mrmvs+PrRCw6fk/Xznv66adNl00dWqarDGirng4vKwzOe5ELnbgkcNKVb7/9Vl599dUs490AAAAAXES0+6S2rIXrufNAQ5221k2bNs205l111VWmYevZZ581Ey9OmjTJTOioXSYffvhhM2FjYWDnaoYAAAAAwkfHu+Wy+2S4de/e3UyoqJM+/vOf/5QHHnjAjNdbtmyZdO7cWf7whz+Yrps67lJ7NdauXVsKg4trlCgAAAAA+LjkkkvMagDDhw83M/737dvX7Nfl2nTNbp18RSdmue+++2T//v1SWBD0AAAAAFzU+vfvL0eOHJH27dt719Z+8sknpXHjxmYN7ptvvlmSkpK8a3Nb13VTJ1zJiU7KAgAAAACFScuWLbMsjF6mTBmzZrc762ZsbKx3CQaXrrdtRdDTAYjnOt67d+8LvSYAAAAAQEEFPZ2FBgAAAAAQ2RijBwAAAACWIegBAAAAgGUIegAAAABCInBCE4TvPSToAQAAALggMTEx5jYtLY138gKdOnXK3MbFxRXcZCwAAAAAkCVUxMZK0aJF5cCBAyagREfb057k5LC8QqifR0NecnKylCpVyhuezxdBDwAAAMAF0QBUsWJF2bFjh+zcudOqd9NxHPF4PCa85mfQc2nI08XZLxRBDwAAAMAFi4+Pl+rVq1vXfdPj8cihQ4fk0ksvzfeWSm0NvdCWPBdBDwAAAEBIaBBKTEy0LujFxcWZ11WYuqQWnisFAAAAAOQKQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALBM2IPetGnTpGrVqpKYmCgtWrSQVatW5Vh+zpw5UrNmTVO+Xr16Mm/ePL/jjuPIyJEjpWLFilKkSBFp166dbNu2za/M4cOHpVevXlKiRAkpVaqU9O/fX06cOOE9fubMGenbt685f2xsrHTp0iXotSxZskQaN24sCQkJcvXVV8sbb7xxwa8PAAAAAC5UWIPe7NmzZejQoTJq1ChZt26dNGjQQNq3by/JyclByy9fvlx69uxpgtn69etNANNt48aN3jLjx4+XqVOnyvTp02XlypVSrFgxc04Nby4NeZs2bZKFCxfKJ598IkuXLpUBAwZ4j2dmZpqQ+NBDD5mgGMyOHTukU6dOcuONN8qGDRtkyJAhcs8998hnn3123q8PAAAAAEIhytEmsDDRFq5mzZrJiy++aO57PB6pXLmyPPjggzJs2LAs5e+88045efKkCWeua6+9Vho2bGiCnb6USpUqySOPPCKPPvqoOX7s2DGpUKGCaW3r0aOHbNmyRWrXri2rV6+Wpk2bmjILFiyQjh07yu7du83jfWnL3tGjR2Xu3Ll++x9//HH59NNP/UKmnl/L6vnO5/UFc/z4cSlZsqR5HdoCGU56/RpSy5cvL9HRYW8MRohQr/ahTu1EvdqHOrUPdWonTwR9B85LNoiVMElLS5O1a9fK8OHDvfv0jdMWtBUrVgR9jO7XFjJf2kLmhjBtZdu3b59fK5y+ERq49LEaxPRWu2u6IU9peX1ubQHs2rVrrq5fzxPY2qfXoi175/v6VGpqqtl8K9P9gOkWTvr8GqbDfR0ILerVPtSpnahX+1Cn9qFO7eSJoO/AebmGsAW9gwcPmi6S2trmS+9v3bo16GM0xAUrr/vd4+6+nMpoGvel4/DKlCnjLZMb2V2LBrPTp0/LkSNH8vz61Lhx42TMmDFZ9h84cMCv+2m4Plj61wP9oIf7rxkIHerVPtSpnahX+1Cn9qFO7eSJoO/AKSkpkR/0EJy2APq2Wmpw1O6e5cqVi4ium1FRUeZawv0hR+hQr/ahTu1EvdqHOrUPdWonTwR9B9YJHiM+6JUtW1ZiYmJk//79fvv1flJSUtDH6P6cyru3uk9n3fQto+P43DKBk6FkZGSYmTize968XIuGMZ3IRV9bXl+f0hk8dQukH6pwf7CUfsgj5VoQOtSrfahTO1Gv9qFO7UOd2ikqQr4D5+X5w3al8fHx0qRJE1m0aJFfWtb7LVu2DPoY3e9bXunMmW75atWqmRDlW0ZbxHTsnVtGb3XCFB0/51q8eLF5bh3Ll1vnupbzeX0AAAAAEAph7bqpXRT79OljJkZp3ry5TJ482cyq2a9fP3O8d+/ectlll5lxa2rw4MHSpk0bmThxolnaYNasWbJmzRqZMWOGN2nrZChjx46V6tWrm+A3YsQIM5OmuxZerVq1pEOHDnLvvfeamTrT09Nl0KBBZqIW3xk3N2/ebCZU0ZY+7QurSygot2Xw/vvvN7NpPvbYY/LHP/7RhMX33nvPzMSZ29cHAAAAANYFPV0uQScZ0QXOdXITDVG6NIE7gcmuXbv8midbtWol77zzjjz55JPyxBNPmDCnM27WrVvXW0aDl4YpXRdPW+5at25tzunbn3XmzJkm3LVt29acv1u3bmbtPV+63MLOnTu99xs1amRu3dUoNERqqHv44YdlypQpcvnll8srr7xiZt7M7esDAAAAAOvW0cO5sY4eLqa1YRAa1KmdqFf7UKf2oU7t5Img70p5yQZ8qwMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAAAACwDEEPAAAAACxD0AMAAAAAyxD0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMtERNCbNm2aVK1aVRITE6VFixayatWqHMvPmTNHatasacrXq1dP5s2b53fccRwZOXKkVKxYUYoUKSLt2rWTbdu2+ZU5fPiw9OrVS0qUKCGlSpWS/v37y4kTJ/zKfPfdd3L99deb56lcubKMHz/e7/gNN9wgUVFRWbZOnTp5y/Tt2zfL8Q4dOlzAuwUAAAAAER70Zs+eLUOHDpVRo0bJunXrpEGDBtK+fXtJTk4OWn758uXSs2dPE8zWr18vXbp0MdvGjRu9ZTSQTZ06VaZPny4rV66UYsWKmXOeOXPGW0ZD3qZNm2ThwoXyySefyNKlS2XAgAHe48ePH5dbbrlFqlSpImvXrpUJEybI6NGjZcaMGd4yH374oezdu9e76TXExMTI73//e79r1mDnW+7dd98N8bsIAAAAAD6cMGvevLkzcOBA7/3MzEynUqVKzrhx44KW7969u9OpUye/fS1atHDuu+8+87PH43GSkpKcCRMmeI8fPXrUSUhIcN59911zf/PmzY6+9NWrV3vLzJ8/34mKinJ+/vlnc//vf/+7U7p0aSc1NdVb5vHHH3dq1KiR7WuZNGmSU7x4cefEiRPefX369HE6d+7snK9jx46Za9XbcNO62bt3r7mFPahX+1CndqJe7UOd2oc6tVNmBH0Hzks2iJUwSktLM61lw4cP9+6Ljo42XS1XrFgR9DG6X1sAfWlr3dy5c83PO3bskH379plzuEqWLGm6hOpje/ToYW61u2bTpk29ZbS8Pre2AHbt2tWU+c1vfiPx8fF+z/Pss8/KkSNHpHTp0lmu7dVXXzXn1xZEX0uWLJHy5cubx9x0000yduxYufTSS4O+vtTUVLP5tiwqj8djtnDS59duseG+DoQW9Wof6tRO1Kt9qFP7UKd28kTQd+C8XENYg97BgwclMzNTKlSo4Ldf72/dujXoYzTEBSuv+93j7r6cymjw8hUbGytlypTxK1OtWrUs53CPBQY9HVeoXTc17AV227z99tvNubZv3y5PPPGE3HrrrSZIajfPQOPGjZMxY8Zk2X/gwAG/rqfh+mAdO3bMfNA1FMMO1Kt9qFM7Ua/2oU7tQ53ayRNB34FTUlIKR9CziQY8nRimefPmfvu1hc+lx+vXry9XXXWVaeVr27ZtlvNo66Zvi6W26OlEMOXKlTMTx4T7Q66Tyei1hPtDjtChXu1DndqJerUPdWof6tROngj6DqyTRBaKoFe2bFnTqrV//36//Xo/KSkp6GN0f07l3Vvdp7Nu+pZp2LCht0zgZC8ZGRlmJk7f8wR7Ht/ncJ08eVJmzZolTz311Dlf85VXXmle948//hg06CUkJJgtkH6owv3BUvohj5RrQehQr/ahTu1EvdqHOrUPdWqnqAj5DpyX5w/rler4tyZNmsiiRYv8ErPeb9myZdDH6H7f8kpnznTLaxdJDWK+ZbRVTMfeuWX09ujRo2Z8oGvx4sXmuXUsn1tGZ+JMT0/3e54aNWpk6bapyz3ouLo//OEP53zNu3fvlkOHDvmFUAAAAAAIpbA3y2g3xX/84x/y5ptvypYtW+SBBx4wLWT9+vUzx3v37u03WcvgwYNlwYIFMnHiRDOOT5c8WLNmjQwaNMibtocMGWImPPn444/l+++/N+eoVKmSWYZB1apVy4ydu/fee83YumXLlpnHazdLLafuuusuE0R1GQddhkGXgZgyZUqWiWDcbpt67sAJVnRdvj//+c/yzTffyP/+9z8TPjt37ixXX321mdgFAAAAAPJD2Mfo3XnnnWaiEV3gXCc50e6VGuTciU927drl10TZqlUreeedd+TJJ580E5tUr17dzLhZt25db5nHHnvMhEVdF09b7lq3bm3O6dundebMmSbcafdJPX+3bt3M2nu+M3V+/vnnMnDgQNPqqN0t9Rp919pTP/zwg3z99dembCDtlqqLrmuI1evQEKlr8z399NNBu2cCAAAAQChE6RoLITkT8oV2O9XQqTP9RMJkLDq2UWcsDXf/ZIQO9Wof6tRO1Kt9qFP7UKd28kTQd+C8ZAO+rQMAAACAZQh6AAAAAGAZgh4AAAAAWIagBwAAAACWIegBAAAAgGUIegAAAABgGYIeAAAAAFiGoAcAAAAAliHoAQAAAIBlCHoAAAAAYBmCHgAAAABYhqAHAAAAAJYh6AEAAACAZQh6AAAAAGAZgh4AAAAAWIagBwAAAACWIegBAAAAgGUIegAAAABgGYIeAAAAAFiGoAcAAAAAliHoAQAAAIBlCHoAAAAAYBmCHgAAAABYhqAHAAAAAJYh6AEAAACAZQh6AAAAAGAZgh4AAAAAWIagBwAAAACWIegBAAAAgGUIegAAAABgGYIeAAAAAFiGoAcAAAAAliHoAQAAAIBlCHoAAAAAYBmCHgAAAABYhqAHAAAAAJYh6AEAAACAZQh6AAAAAGAZgh4AAAAAWIagBwAAAACWIegBAAAAgGUIegAAAABgmYgIetOmTZOqVatKYmKitGjRQlatWpVj+Tlz5kjNmjVN+Xr16sm8efP8jjuOIyNHjpSKFStKkSJFpF27drJt2za/MocPH5ZevXpJiRIlpFSpUtK/f385ceKEX5nvvvtOrr/+evM8lStXlvHjx/sdf+ONNyQqKspv07J5vRYAAAAAsCrozZ49W4YOHSqjRo2SdevWSYMGDaR9+/aSnJwctPzy5culZ8+eJpitX79eunTpYraNGzd6y2ggmzp1qkyfPl1WrlwpxYoVM+c8c+aMt4yGvE2bNsnChQvlk08+kaVLl8qAAQO8x48fPy633HKLVKlSRdauXSsTJkyQ0aNHy4wZM/yuR4Pi3r17vdvOnTv9jufmWgAAAAAglKIcbXIKI23Ba9asmbz44ovmvsfjMa1nDz74oAwbNixL+TvvvFNOnjxpwpnr2muvlYYNG5owpS+nUqVK8sgjj8ijjz5qjh87dkwqVKhgWuB69OghW7Zskdq1a8vq1auladOmpsyCBQukY8eOsnv3bvP4l156Sf7yl7/Ivn37JD4+3pTR65k7d65s3brV3NfzDRkyRI4ePRr0teXmWgKlpqaazTdw6vtx5MgREyrDSevmwIEDUq5cOYmODvvfCBAi1Kt9qFM7Ua/2oU7tQ53ayRNB34E1G5QuXdpkinNlg1gJo7S0NNNaNnz4cO8+ffO0e+OKFSuCPkb3awugL20h0wCmduzYYcKZnsNVsmRJEyj1sRqu9Fa7a7ohT2l5fW5tdevatasp85vf/MYb8tznefbZZ03o0jdYaXdPbfXTD0Djxo3lmWeekTp16uT6WgKNGzdOxowZk2W/frjC3Qqor1E/VBpgw/0hR+hQr/ahTu1EvdqHOrUPdWonTwR9B05JScl12bAGvYMHD0pmZqZp4fKl991Ws0AanIKV1/3ucXdfTmXKly/vdzw2NlbKlCnjV6ZatWpZzuEe06BXo0YNee2116R+/fqm8p977jlp1aqV6RJ6+eWX5+paAmno9Q2yboue/gUhElr0dBxiJPw1A6FDvdqHOrUT9Wof6tQ+1KmdPBH0HThwPpCIDXqFXcuWLc3m0pBXq1Ytefnll+Xpp58+r3MmJCSYLZB+qML9wVL6IY+Ua0HoUK/2oU7tRL3ahzq1D3VqEccRyUgVSTspMWcOS3R0hbB/B87L84c16JUtW1ZiYmJk//79fvv1flJSUtDH6P6cyru3uk9nuvQto+P43DKBk71kZGSYmTh9zxPseXyfI1BcXJw0atRIfvzxx1xfCwAAAIA8BrDMdJH0UyLpp31ufX8+JZJxJvtjfvtyKCeOmb2ydJlrRAatLFTVFNagp+PfmjRpIosWLTIzZ7pNo3p/0KBBQR+jLWh6XCdBcenMmW7Lmna31IClZdwwpd0fdezdAw884D2HTqCi4wP1+dXixYvNc+v4ObeMTsaSnp5uApz7PNpd0x2fF0i7oX7//fdmUpfcXgsAAABgjSwB7Ew2ISsgWPmFspzC2dlyTmaBvqyozDQpbMLedVPHo/Xp08dMjNK8eXOZPHmymVWzX79+5njv3r3lsssuM5OUqMGDB0ubNm1k4sSJ0qlTJ5k1a5asWbPGu+yBNpdrCBw7dqxUr17dhK0RI0aY2S/dMKndKzt06CD33nuvmalTw5wGS50cRcupu+66y0yKoss4PP7442b5hilTpsikSZO81/7UU0+ZGT+vvvpqExx1CQZdXuGee+7J9bUAAAAA+S4zQyQjLy1bOYStnEKZJ6NgKzMqWiSumEhckbNb0YDbxCD7gpSLDdz/68+emAQ5eOiI+M/wEfnCHvR0uQSdUVIXFdcJSrTlS5c6cCcw2bVrl19fVB0H984778iTTz4pTzzxhAlQOuNm3bp1vWUee+wxExZ1XTwNYK1btzbn9B28OHPmTBPu2rZta87frVs3s96d7+yYn3/+uQwcONC0+mk3U71G37X2dPZNDYvu5CxaTtf506Ub8nItAAAAuEh5Ms+zZct3y6G8G+4KvEUqSiS+WECIOkfY8tuKZl/GN5TFxGnrSv6+FI9HCqOwr6OHnGlXTw2duVkrI79p11Yd26gzloZ7ICpCh3q1D3VqJ+rVPtRphNMv9xnn6HYYEMqctFNy6thBKRoXJVFZxodlE8oyf10/ucCcq4UrNjGHIOa7L4fWspj4/A9gF+Hv6vE8ZIOwt+gBAAAAeZsJ0TeABWsBy6FlK7eTc2j5PNJYU+xCqtKv+2Auw5YJZTm1kgW0lml5SwIYckbQAwAAQIhmQkzLZXfDXIStbGdM1ABWwB3SYhLOEbp+CVtObKKcSnekaMmyEhVf9NzdDv3GiCXq3PkF+7pgNYIeAADAxTQVvbdl61wzIeZi/FdgKHMKeCyTdg8MOqHGuVrCcjNezKcLY3RMri7H8XgkJTlZipQvL1GENoQZQQ8AACBcdIbC1OO/LMqcq+6GuZh2Pli5Ap6KXqJifp2IIzcTauTY7TCbLoz6+Bi+ygLZ4bcDAACEvgVJW3Y0xOiMghoyzM9n93nvZ/qX8x47u/mWC7zvW87vcRnZnDPIc/udJ+C5c3UtF/a4KCdTkgq6BSzoVPTnGuMVbCzYOVrLdCZEAGFF0AMAILc0LPh9cQ8IFXkOJhm5P2dmhhQ9flSkWNFfzxXykBSi11DQrUeFlP90GFG56Gp4jlkOc9OFsSCmogcQEQh6AHCx09aXLF/cQx0i8hBo8r3VJ9i15PJxYaRTNIR3kZ1QifplvFN07C/d+/RWxzJ575/dvMfcn2OCP863nDl29lx+5/A9v3vMp1xOz52P1+KRKDlwNEXKVbxCojXAEcAAhBBBD7kW9eE9cume7yUqVgckh+mvgRGz7GOEXEcI3g+tybKZGRJ1QeMcIuD94LPhX6fp6RIV7eQu0BR01zFbBf2Sn8dAk8PjnKhYOZOWLolFikqUaZUJFlSCBBq/cBLw3Od5Lf6PCwg05wxszCro5fGIczpaJDaBkAcg5Ah6yL3D/5O4w//lHbOMhgL+R2CXkNap+wU+X1pQLqTlJdSB5gLPqdeYz60xOpvfseRkSWA2PwBALvD9Drnm3Dpejuz/SUqVKiXR0QXZohem1sOwdKEp+Of0OI4cOXpUSpcqTb1aUq8exyNHjhyV0peWk2htqb2Q7ml0JQMAoFAi6CH3LmssaXGXi5QvT9cbm3g8kp6cTL3aVqeJ1CkAABczOsoDAAAAgGUIegAAAABgGYIeAAAAAFiGoAcAAAAAliHoAQAAAIBlCHoAAAAAYBmCHgAAAABYhqAHAAAAAJYh6AEAAACAZQh6AAAAAGAZgh4AAAAAWIagBwAAAACWIegBAAAAgGUIegAAAABgmdhwXwBy5jiOuT1+/HjY3yqPxyMpKSmSmJgo0dH8jcAW1Kt9qFM7Ua/2oU7tQ53ayRNB34HdTOBmhJwQ9CKcfqhU5cqVw30pAAAAACIkI5QsWTLHMlFObuIgwvoXhD179kjx4sUlKioq7H9B0MD5008/SYkSJcJ6LQgd6tU+1KmdqFf7UKf2oU7tdDyCvgNrdNOQV6lSpXO2LtKiF+G0Ai+//HKJJPoBD/eHHKFHvdqHOrUT9Wof6tQ+1KmdSkTId+BzteS5GGgFAAAAAJYh6AEAAACAZQh6yLWEhAQZNWqUuYU9qFf7UKd2ol7tQ53ahzq1U0Ih/Q7MZCwAAAAAYBla9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPTgZ9q0aVK1alVJTEyUFi1ayKpVq3J8h+bMmSM1a9Y05evVqyfz5s3jHS3k9frGG29IVFSU36aPQ+RYunSp3HbbbVKpUiVTP3Pnzj3nY5YsWSKNGzc2M4ZdffXVpp5ReOtU6zPw91S3ffv2Fdg1I2fjxo2TZs2aSfHixaV8+fLSpUsX+eGHH875tvHvql11yr+pke+ll16S+vXrexdDb9mypcyfP9+K31OCHrxmz54tQ4cONdPHrlu3Tho0aCDt27eX5OTkoO/S8uXLpWfPntK/f39Zv369+R+ebhs3buRdLcT1qvR/dHv37vVuO3fuLNBrRs5Onjxp6lEDfG7s2LFDOnXqJDfeeKNs2LBBhgwZIvfcc4989tlnvNWFtE5d+iXT93dVv3wiMnz11VcycOBA+eabb2ThwoWSnp4ut9xyi6nr7PDvqn11qvg3NbJdfvnl8re//U3Wrl0ra9askZtuukk6d+4smzZtKvy/pw5wVvPmzZ2BAwd634/MzEynUqVKzrhx44K+R927d3c6derkt69FixbOfffdx3taiOv19ddfd0qWLFmAV4gLof8b/+ijj3Is89hjjzl16tTx23fnnXc67du3580vpHX65ZdfmnJHjhwpsOvChUlOTjZ19tVXX2Vbhn9X7atT/k0tnEqXLu288sorhf73lBY9GGlpaeYvGe3atfO+I9HR0eb+ihUrgr5Lut+3vNKWouzKo3DUqzpx4oRUqVJFKleunONftVA48Ltqr4YNG0rFihXl5ptvlmXLloX7cpCDY8eOmdsyZcpkW4bfVfvqVPFvauGRmZkps2bNMq202oWzsP+eEvRgHDx40Hy4K1So4PeO6P3sxnzo/ryUR+Go1xo1ashrr70m//rXv+Ttt98Wj8cjrVq1kt27dxfQVSPUsvtdPX78uJw+fZo3vBDScDd9+nT54IMPzKZ/lLnhhhtM92xEHv3/qHaZvu6666Ru3brZluPfVfvqlH9TC4fvv/9eLrnkEjOO/f7775ePPvpIateuXeh/T2PDfQEAIov+Bcv3r1ga8mrVqiUvv/yyPP3002G9NgC/fnnUzff3dPv27TJp0iR56623eJsijI7r0vE7X3/9dbgvBQVcp/ybWjjUqFHDjGHXVtr3339f+vTpY8ZkZhf2Cgta9GCULVtWYmJiZP/+/X7viN5PSkoK+i7p/ryUR+Go10BxcXHSqFEj+fHHH/PpKpHfsvtd1QkCihQpQgVYonnz5vyeRqBBgwbJJ598Il9++aWZ9CEn/LtqX50G4t/UyBQfH29mpG7SpImZXVUnx5oyZUqh/z0l6MH7AdcP96JFi/y6Jej97Poo637f8kpnocquPApHvQbSrp/apUG7iqFw4nf14qB/jeb3NHLovDoaCLQL2OLFi6VatWrnfAy/q/bVaSD+TS0cPB6PpKamFv7f03DPBoPIMWvWLCchIcF54403nM2bNzsDBgxwSpUq5ezbt88cv/vuu51hw4Z5yy9btsyJjY11nnvuOWfLli3OqFGjnLi4OOf7778P46vAhdbrmDFjnM8++8zZvn27s3btWqdHjx5OYmKis2nTJt7cCJGSkuKsX7/ebPq/8eeff978vHPnTnNc61Pr1fV///d/TtGiRZ0///nP5nd12rRpTkxMjLNgwYIwvgpcSJ1OmjTJmTt3rrNt2zbz/9zBgwc70dHRzhdffMEbGyEeeOABM4PxkiVLnL1793q3U6dOecvw76r9dcq/qZFv2LBhZubUHTt2ON999525HxUV5Xz++eeF/veUoAc/L7zwgnPFFVc48fHxZlr+b775xnusTZs2Tp8+ffzKv/fee84111xjyuv07Z9++invaCGv1yFDhnjLVqhQwenYsaOzbt26MF05cppaP3Bz61FvtV4DH9OwYUNTr1deeaWZ8huFt06fffZZ56qrrjJ/hClTpoxzww03OIsXLw7jK0CgYPWpm+/vHv+u2l+n/Jsa+f74xz86VapUMf8+litXzmnbtq035BX239Mo/U+4WxUBAAAAAKHDGD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAADLEPQAAAAAwDIEPQAALBYVFSVz584N92UAAAoYQQ8AgHzSt29fE7QCtw4dOvCeAwDyVWz+nh4AgIubhrrXX3/db19CQkLYrgcAcHGgRQ8AgHykoS4pKclvK126tDmmrXsvvfSS3HrrrVKkSBG58sor5f333/d7/Pfffy833XSTOX7ppZfKgAED5MSJE35lXnvtNalTp455rooVK8qgQYP8jh88eFC6du0qRYsWlerVq8vHH39MnQOA5Qh6AACE0YgRI6Rbt27y7bffSq9evaRHjx6yZcsWc+zkyZPSvn17EwxXr14tc+bMkS+++MIvyGlQHDhwoAmAGgo1xF199dV+zzFmzBjp3r27fPfdd9KxY0fzPIcPHy7w1woAKDhRjuM4Bfh8AABcVGP03n77bUlMTPTb/8QTT5hNW/Tuv/9+E9Zc1157rTRu3Fj+/ve/yz/+8Q95/PHH5aeffpJixYqZ4/PmzZPbbrtN9uzZIxUqVJDLLrtM+vXrJ2PHjg16DfocTz75pDz99NPe8HjJJZfI/PnzGSsIABZjjB4AAPnoxhtv9AtyqkyZMt6fW7Zs6XdM72/YsMH8rC17DRo08IY8dd1114nH45EffvjBhDgNfG3bts3xGurXr+/9Wc9VokQJSU5OvuDXBgCIXAQ9AADykQarwK6UoaLj9nIjLi7O774GRA2LAAB7MUYPAIAw+uabb7Lcr1WrlvlZb3Xsnna3dC1btkyio6OlRo0aUrx4calataosWrSowK8bABDZaNEDACAfpaamyr59+/z/8Y2NlbJly5qfdYKVpk2bSuvWrWXmzJmyatUqefXVV80xnTRl1KhR0qdPHxk9erQcOHBAHnzwQbn77rvN+Dyl+3WcX/ny5c3snSkpKSYMajkAwMWLoAcAQD5asGCBWfLAl7bGbd261Tsj5qxZs+RPf/qTKffuu+9K7dq1zTFdDuGzzz6TwYMHS7Nmzcx9naHz+eef955LQ+CZM2dk0qRJ8uijj5oAeccdd1CnAHCRY9ZNAADCRMfKffTRR9KlSxfqAAAQUozRAwAAAADLEPQAAAAAwDKM0QMAIEwcx+G9BwDkC1r0AAAAAMAyBD0AAAAAsAxBDwAAAAAsQ9ADAAAAAMsQ9AAAAADAMgQ9AAAAALAMQQ8AAAAALEPQAwAAAACxy/8DFgNG8UTvn68AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('DNN Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f181829",
   "metadata": {},
   "source": [
    "## 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9827f035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集评估:\n",
      "  RMSE: 0.002852\n",
      "  R²: -0.000177\n",
      "  Correlation: -0.003127\n",
      "\n",
      "预测统计:\n",
      "  Mean: 0.000013\n",
      "  Std: 0.000029\n"
     ]
    }
   ],
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('../models/dnn_best.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 验证集预测\n",
    "with torch.no_grad():\n",
    "    val_pred_scaled = model(X_val_t.to(device)).cpu().numpy()\n",
    "\n",
    "# 反归一化\n",
    "val_pred = target_scaler.inverse_transform(val_pred_scaled).flatten()\n",
    "y_val_orig = target_scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 评估\n",
    "rmse = np.sqrt(mean_squared_error(y_val_orig, val_pred))\n",
    "r2 = r2_score(y_val_orig, val_pred)\n",
    "corr = np.corrcoef(y_val_orig, val_pred)[0, 1]\n",
    "\n",
    "print(f\"验证集评估:\")\n",
    "print(f\"  RMSE: {rmse:.6f}\")\n",
    "print(f\"  R²: {r2:.6f}\")\n",
    "print(f\"  Correlation: {corr:.6f}\")\n",
    "print(f\"\\n预测统计:\")\n",
    "print(f\"  Mean: {val_pred.mean():.6f}\")\n",
    "print(f\"  Std: {val_pred.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a500bf4",
   "metadata": {},
   "source": [
    "## 测试集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4b14950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据形状: (2881, 150)\n"
     ]
    }
   ],
   "source": [
    "# 准备测试数据\n",
    "# 需要训练集尾部数据\n",
    "train_tail = train_clean.tail(WINDOW_SIZE + 100).copy()\n",
    "\n",
    "# 合并\n",
    "test_with_history = pd.concat([train_tail, test_featured], ignore_index=True)\n",
    "test_with_history = test_with_history.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# 标准化\n",
    "X_test_scaled = feature_scaler.transform(test_with_history[feature_cols])\n",
    "\n",
    "# 创建窗口\n",
    "X_test_windowed = []\n",
    "for i in range(WINDOW_SIZE, len(X_test_scaled)):\n",
    "    window_features = X_test_scaled[i-WINDOW_SIZE:i].flatten()\n",
    "    X_test_windowed.append(window_features)\n",
    "X_test_windowed = np.array(X_test_windowed)\n",
    "\n",
    "# 只取测试集部分\n",
    "n_test = len(test_df)\n",
    "X_test_windowed = X_test_windowed[-n_test:]\n",
    "\n",
    "print(f\"测试数据形状: {X_test_windowed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "900f8859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测数量: 2881\n",
      "预测均值: -0.000004\n",
      "预测标准差: 0.000019\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "X_test_t = torch.FloatTensor(X_test_windowed).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred_scaled = model(X_test_t).cpu().numpy()\n",
    "\n",
    "# 反归一化\n",
    "test_predictions = target_scaler.inverse_transform(test_pred_scaled).flatten()\n",
    "\n",
    "print(f\"预测数量: {len(test_predictions)}\")\n",
    "print(f\"预测均值: {test_predictions.mean():.6f}\")\n",
    "print(f\"预测标准差: {test_predictions.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f376697",
   "metadata": {},
   "source": [
    "## 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f4e5aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 提交文件已保存: ..\\submissions\\dnn_submission.csv\n",
      "\n",
      "预览:\n",
      "            Timestamp  Prediction\n",
      "0 2025-10-23 23:30:00   -0.000021\n",
      "1 2025-10-23 23:45:00   -0.000021\n",
      "2 2025-10-24 00:00:00   -0.000022\n",
      "3 2025-10-24 00:15:00   -0.000021\n",
      "4 2025-10-24 00:30:00   -0.000021\n",
      "5 2025-10-24 00:45:00   -0.000014\n",
      "6 2025-10-24 01:00:00   -0.000010\n",
      "7 2025-10-24 01:15:00   -0.000015\n",
      "8 2025-10-24 01:30:00   -0.000011\n",
      "9 2025-10-24 01:45:00   -0.000013\n",
      "\n",
      "统计:\n",
      "count    2881.000000\n",
      "mean       -0.000004\n",
      "std         0.000019\n",
      "min        -0.000055\n",
      "25%        -0.000017\n",
      "50%        -0.000006\n",
      "75%         0.000009\n",
      "max         0.000049\n",
      "Name: Prediction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 创建提交\n",
    "submission_df = pd.DataFrame({\n",
    "    'Timestamp': test_df['Timestamp'].values[:len(test_predictions)],\n",
    "    'Prediction': test_predictions\n",
    "})\n",
    "\n",
    "# 保存\n",
    "submission_dir = Path('../submissions')\n",
    "submission_dir.mkdir(exist_ok=True)\n",
    "\n",
    "submission_file = submission_dir / 'dnn_submission.csv'\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"✅ 提交文件已保存: {submission_file}\")\n",
    "print(f\"\\n预览:\")\n",
    "print(submission_df.head(10))\n",
    "print(f\"\\n统计:\")\n",
    "print(submission_df['Prediction'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46895556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型已保存\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\n",
    "model_dir = Path('../models')\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'feature_cols': feature_cols,\n",
    "    'window_size': WINDOW_SIZE,\n",
    "}, model_dir / 'dnn_model.pth')\n",
    "\n",
    "import joblib\n",
    "joblib.dump(feature_scaler, model_dir / 'dnn_feature_scaler.pkl')\n",
    "joblib.dump(target_scaler, model_dir / 'dnn_target_scaler.pkl')\n",
    "\n",
    "print(\"✅ 模型已保存\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e843b",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### DNN/MLP 模型架构 (基于论文):\n",
    "- **Input**: Window_size × N_features (展平的滑动窗口)\n",
    "- **Hidden Layer 1**: 256 neurons + BatchNorm + ReLU + Dropout\n",
    "- **Hidden Layer 2**: 128 neurons + BatchNorm + ReLU + Dropout\n",
    "- **Hidden Layer 3**: 64 neurons + BatchNorm + ReLU + Dropout\n",
    "- **Output**: 1 (预测值)\n",
    "\n",
    "### 论文发现:\n",
    "- MLP 作为基准模型\n",
    "- LSTM 变体（特别是 BD-LSTM）表现最佳\n",
    "- 单变量模型通常优于多变量模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6117a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
