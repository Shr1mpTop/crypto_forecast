{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d20936",
   "metadata": {},
   "source": [
    "# Timestamp Prediction: Compliance-First Multi-Model Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7bda0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and data loading\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f83193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp  Open  High   Low  Close  Volume  Target\n",
      "0 2012-01-01 10:00:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
      "1 2012-01-01 10:15:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
      "2 2012-01-01 10:30:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
      "3 2012-01-01 10:45:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
      "4 2012-01-01 11:00:00  4.58  4.58  4.58   4.58     0.0     0.0\n",
      "            Timestamp      Open      High       Low     Close     Volume\n",
      "0 2025-10-23 23:30:00  110113.0  110113.0  110001.0  110093.0   5.994213\n",
      "1 2025-10-23 23:45:00  110093.0  110111.0  110003.0  110111.0   5.027084\n",
      "2 2025-10-24 00:00:00  110110.0  110278.0  110033.0  110267.0  29.892445\n",
      "3 2025-10-24 00:15:00  110228.0  110463.0  110180.0  110197.0  16.283404\n",
      "4 2025-10-24 00:30:00  110197.0  110517.0  110169.0  110418.0   8.827779\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "root = Path('..').resolve()\n",
    "data_dir = root / 'data'\n",
    "train_path = data_dir / 'train.csv'\n",
    "test_path = data_dir / 'test.csv'\n",
    "assert train_path.exists() and test_path.exists(), 'train.csv or test.csv not found'\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "train_df['Timestamp'] = pd.to_datetime(train_df['Timestamp'])\n",
    "test_df['Timestamp'] = pd.to_datetime(test_df['Timestamp'])\n",
    "train_df = train_df.sort_values('Timestamp').reset_index(drop=True)\n",
    "test_df = test_df.sort_values('Timestamp').reset_index(drop=True)\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456c2cf",
   "metadata": {},
   "source": [
    "# Data preprocessing and feature engineering\n",
    "We build leakage-free temporal features and a log-return target. No test leakage or sign flipping is used; direction is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d9c69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 387335, Val rows: 96834, Test rows: 2849\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering utilities\n",
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out['hour'] = out['Timestamp'].dt.hour\n",
    "    out['day'] = out['Timestamp'].dt.day\n",
    "    out['weekday'] = out['Timestamp'].dt.weekday\n",
    "    out['month'] = out['Timestamp'].dt.month\n",
    "    return out\n",
    "\n",
    "def add_price_features(df: pd.DataFrame, max_lag: int = 16) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out['ret_1'] = np.log(out['Close'] / out['Close'].shift(1))\n",
    "    for lag in [1,2,3,4,6,8,12,16]:\n",
    "        out[f'lag_close_{lag}'] = out['Close'].shift(lag)\n",
    "        out[f'lag_ret_{lag}'] = out['ret_1'].shift(lag)\n",
    "    for w in [4,8,16,32]:\n",
    "        out[f'roll_ret_mean_{w}'] = out['ret_1'].rolling(w).mean()\n",
    "        out[f'roll_ret_std_{w}'] = out['ret_1'].rolling(w).std()\n",
    "        out[f'roll_close_mean_{w}'] = out['Close'].rolling(w).mean()\n",
    "        out[f'roll_close_std_{w}'] = out['Close'].rolling(w).std()\n",
    "    out = out.replace([np.inf, -np.inf], np.nan)\n",
    "    return out\n",
    "\n",
    "def build_dataset(df: pd.DataFrame, is_train: bool = True):\n",
    "    df = add_time_features(df)\n",
    "    df = add_price_features(df)\n",
    "    if is_train:\n",
    "        # competition-compliant target: log-return to next step using only train data\n",
    "        df['Target'] = np.log(df['Close'].shift(-1) / df['Close'])\n",
    "        df = df.iloc[:-1]  # last row has no next close\n",
    "    feature_cols = [c for c in df.columns if c not in ['Timestamp','Open','High','Low','Close','Volume','Target']]\n",
    "    df = df.dropna(subset=feature_cols + (['Target'] if is_train else []))\n",
    "    return df, feature_cols\n",
    "\n",
    "# Build train/val sets\n",
    "train_feat, feature_cols = build_dataset(train_df, is_train=True)\n",
    "X = train_feat[feature_cols].values\n",
    "y = train_feat['Target'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s = scaler.transform(X_val)\n",
    "test_feat, _ = build_dataset(test_df, is_train=False)\n",
    "X_test_s = scaler.transform(test_feat[feature_cols].values)\n",
    "print(f'Train rows: {len(X_train)}, Val rows: {len(X_val)}, Test rows: {len(X_test_s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca200b",
   "metadata": {},
   "source": [
    "# Baseline compliance method\n",
    "A simple ridge regression on engineered features, fixed direction (no sign flip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8965f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge baseline: Pearson=0.00547 MAE=0.001601 RMSE=0.002513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.00547324182578654),\n",
       " 0.001600591550523547,\n",
       " np.float64(0.0025130183195143643))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline ridge regression\n",
    "def evaluate(pred, name):\n",
    "    pearson = pearsonr(pred, y_val)[0]\n",
    "    mae = mean_absolute_error(y_val, pred)\n",
    "    mse = mean_squared_error(y_val, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"{name}: Pearson={pearson:.5f} MAE={mae:.6f} RMSE={rmse:.6f}\")\n",
    "    return pearson, mae, rmse\n",
    "\n",
    "ridge = Ridge(alpha=1.0, random_state=42)\n",
    "ridge.fit(X_train_s, y_train)\n",
    "val_pred_ridge = ridge.predict(X_val_s)\n",
    "evaluate(val_pred_ridge, 'Ridge baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd53799",
   "metadata": {},
   "source": [
    "# LightGBM model\n",
    "Train a gradient boosted trees model tuned for small learning rate and moderate depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354eb6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM: Pearson=0.03278 MAE=0.001579 RMSE=0.002493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.03278381182759346),\n",
       " 0.0015785081800397814,\n",
       " np.float64(0.0024930491707538037))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train LightGBM\n",
    "lgb_train = lgb.Dataset(X_train_s, label=y_train)\n",
    "lgb_val = lgb.Dataset(X_val_s, label=y_val, reference=lgb_train)\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 63,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'min_child_samples': 50,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'verbosity': -1,\n",
    "    'seed': 42,\n",
    "}\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=1200,\n",
    "    valid_sets=[lgb_val],\n",
    "    callbacks=[lgb.early_stopping(80, verbose=False)]\n",
    ")\n",
    "val_pred_lgb = lgb_model.predict(X_val_s)\n",
    "evaluate(val_pred_lgb, 'LightGBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266ed8d",
   "metadata": {},
   "source": [
    "# XGBoost model\n",
    "Parallel gradient boosting baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e4b6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Pearson=0.02633 MAE=0.001579 RMSE=0.002494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.02632717586681382),\n",
       " 0.0015792742906270947,\n",
       " np.float64(0.002493501782157594))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_s, label=y_train)\n",
    "dval = xgb.DMatrix(X_val_s, label=y_val)\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'lambda': 0.1,\n",
    "    'alpha': 0.1,\n",
    "    'seed': 42,\n",
    "}\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=1500,\n",
    "    evals=[(dval, 'val')],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=False\n",
    ")\n",
    "val_pred_xgb = xgb_model.predict(xgb.DMatrix(X_val_s))\n",
    "evaluate(val_pred_xgb, 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f179b",
   "metadata": {},
   "source": [
    "# LightGBM + XGBoost ensemble\n",
    "Weighted averaging without sign flipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552ffbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble (LGB+XGB): Pearson=0.03062 MAE=0.001579 RMSE=0.002493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.03061500297118868),\n",
       " 0.0015788541271964068,\n",
       " np.float64(0.002493188393189832))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble\n",
    "w_lgb, w_xgb = 0.5, 0.5\n",
    "val_pred_ens = w_lgb * val_pred_lgb + w_xgb * val_pred_xgb\n",
    "evaluate(val_pred_ens, 'Ensemble (LGB+XGB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf63ba7",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM model\n",
    "Sequence-to-one forecasting on scaled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df8538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387303, 32, 37) (96834, 32, 37)\n",
      "BiLSTM: Pearson=0.02597 MAE=0.001644 RMSE=0.002539\n",
      "BiLSTM: Pearson=0.02597 MAE=0.001644 RMSE=0.002539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.025973121079580597),\n",
       " 0.0016442828235145928,\n",
       " np.float64(0.002538985404502768))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare sequences for BiLSTM\n",
    "def make_sequences(X_arr, y_arr, lookback=32):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(lookback, len(X_arr)):\n",
    "        X_seq.append(X_arr[i-lookback:i])\n",
    "        y_seq.append(y_arr[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "lookback = 32\n",
    "X_train_seq, y_train_seq = make_sequences(X_train_s, y_train, lookback)\n",
    "X_val_seq, y_val_seq = make_sequences(np.vstack([X_train_s[-lookback:], X_val_s]), np.concatenate([y_train[-lookback:], y_val]), lookback)\n",
    "print(X_train_seq.shape, X_val_seq.shape)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "bilstm = keras.Sequential([\n",
    "    layers.Input(shape=(lookback, X_train_s.shape[1])),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Bidirectional(layers.LSTM(32)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "bilstm.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
    "history = bilstm.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
    ")\n",
    "val_pred_bilstm = bilstm.predict(X_val_seq, verbose=0).reshape(-1)\n",
    "evaluate(val_pred_bilstm, 'BiLSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa30c6",
   "metadata": {},
   "source": [
    "# Model evaluation and comparison\n",
    "Collect validation metrics and choose the top performer (by Pearson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6cdfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pearson",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mae",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rmse",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "05cdacbe-78dc-4b00-916e-5039d3be1103",
       "rows": [
        [
         "1",
         "LightGBM",
         "0.03278381182759346",
         "0.0015785081800397814",
         "0.0024930491707538037"
        ],
        [
         "3",
         "Ensemble_LGB_XGB",
         "0.03061500297118868",
         "0.0015788541271964068",
         "0.002493188393189832"
        ],
        [
         "2",
         "XGBoost",
         "0.02632717586681382",
         "0.0015792742906270947",
         "0.002493501782157594"
        ],
        [
         "4",
         "BiLSTM",
         "0.025973121079580597",
         "0.0016442828235145928",
         "0.002538985404502768"
        ],
        [
         "0",
         "Ridge",
         "0.00547324182578654",
         "0.001600591550523547",
         "0.0025130183195143643"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pearson</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.032784</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.002493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble_LGB_XGB</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.002493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.002494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>0.025973</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.002539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.002513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model   pearson       mae      rmse\n",
       "1          LightGBM  0.032784  0.001579  0.002493\n",
       "3  Ensemble_LGB_XGB  0.030615  0.001579  0.002493\n",
       "2           XGBoost  0.026327  0.001579  0.002494\n",
       "4            BiLSTM  0.025973  0.001644  0.002539\n",
       "0             Ridge  0.005473  0.001601  0.002513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model by Pearson: LightGBM\n",
      "Saved submission: E:\\github\\crypto_forecast\\submissions\\timestamp_prediction_submission.csv\n",
      "Saved submission: E:\\github\\crypto_forecast\\submissions\\timestamp_prediction_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Compare and select best model\n",
    "results = []\n",
    "def add_result(name, val_pred):\n",
    "    pearson = pearsonr(val_pred, y_val)[0]\n",
    "    mae = mean_absolute_error(y_val, val_pred)\n",
    "    mse = mean_squared_error(y_val, val_pred)  # older sklearn compatibility\n",
    "    rmse = np.sqrt(mse)\n",
    "    results.append({'model': name, 'pearson': pearson, 'mae': mae, 'rmse': rmse})\n",
    "\n",
    "add_result('Ridge', val_pred_ridge)\n",
    "add_result('LightGBM', val_pred_lgb)\n",
    "add_result('XGBoost', val_pred_xgb)\n",
    "add_result('Ensemble_LGB_XGB', val_pred_ens)\n",
    "add_result('BiLSTM', val_pred_bilstm)\n",
    "results_df = pd.DataFrame(results).sort_values('pearson', ascending=False)\n",
    "display(results_df)\n",
    "best_model = results_df.iloc[0]['model']\n",
    "print(f'Best model by Pearson: {best_model}')\n",
    "\n",
    "# Prepare test predictions for each model\n",
    "test_pred_ridge = ridge.predict(X_test_s)\n",
    "test_pred_lgb = lgb_model.predict(X_test_s)\n",
    "test_pred_xgb = xgb_model.predict(xgb.DMatrix(X_test_s))\n",
    "test_pred_ens = w_lgb * test_pred_lgb + w_xgb * test_pred_xgb\n",
    "\n",
    "# BiLSTM test prediction\n",
    "def make_test_sequences(X_hist, X_future, lookback=32):\n",
    "    concat = np.vstack([X_hist, X_future])\n",
    "    X_seq = []\n",
    "    for i in range(len(X_hist), len(concat)):\n",
    "        start = i - lookback\n",
    "        end = i\n",
    "        if start >= 0:\n",
    "            X_seq.append(concat[start:end])\n",
    "    return np.array(X_seq)\n",
    "\n",
    "X_hist = X_train_s[-lookback:]\n",
    "X_test_seq = make_test_sequences(X_hist, X_test_s, lookback)\n",
    "test_pred_bilstm = bilstm.predict(X_test_seq, verbose=0).reshape(-1)\n",
    "\n",
    "test_preds_map = {\n",
    "    'Ridge': test_pred_ridge,\n",
    "    'LightGBM': test_pred_lgb,\n",
    "    'XGBoost': test_pred_xgb,\n",
    "    'Ensemble_LGB_XGB': test_pred_ens,\n",
    "    'BiLSTM': test_pred_bilstm,\n",
    "}\n",
    "\n",
    "best_test_pred = test_preds_map[best_model]\n",
    "submission = pd.DataFrame({'row_id': np.arange(len(best_test_pred)), 'Target': best_test_pred})\n",
    "sub_path = root / 'submissions' / 'timestamp_prediction_submission.csv'\n",
    "sub_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "submission.to_csv(sub_path, index=False)\n",
    "print(f'Saved submission: {sub_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6117a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
